{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Data Preparation:</u>\n",
    "\n",
    "> * <a href=\"#*-Data-Cleaning\">DATA CLEANING</a>\n",
    "> * <a href=\"#*-Data-Reduction\">DATA REDUCTION</a>\n",
    "    * <a href=\"#Scaling\">Scaling</a>\n",
    "> * <a href=\"#*-Data-transformation\">DATA TRANSFORMATION</a>\n",
    "    * <a href=\"#Arrenging-data-Country-Wise\">Arranging data Country-Wise</a>\n",
    "    * <a href=\"#Explaination-of-Pooled-Datasets-(bulk-&-four)\">Pooled Datasets</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we have the raw data for our analysis, we can move forward for our next phase i.e. Data-Preparation.<br />\n",
    "* The data-preparation is considered to be the <u>most time consuming phase</u> of any datascience project.<br />\n",
    "* On an average, an idal data-science project's <b>90%</b> of time is spent during Data-Collection and Data-Preparation.<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we collect any kind of the raw-data from various sourcev, it has a lot of the vulnerabilities.<br />\n",
    "Most often, these are of following types:\n",
    "1. NAs and NaNs\n",
    "2. Missing data values\n",
    "3. Incorrect data values\n",
    "<br /><br />\n",
    "Checking for these flaws in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# sample NA values\n",
    "check.Confirmed[which(str_detect(check.Confirmed$Country.Region, \"Cruise Ship\")),]\n",
    "\n",
    "# sample wrong data \"french guiana\" the data value can not decrease on next day\n",
    "check.Confirmed[which(str_detect(check.Confirmed$Province.State, \"French Guiana\")),]\n",
    "\n",
    "# sample blank data ---> State (to be replaced by 'Others')\n",
    "head(check.Recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "So, there are also many issues (like <u>blanks in the place of states' name</u> and data of a <u>Cruise Ship among countries' data</u>) with our available datasets.<br />\n",
    "To get rid of these issues, the data-cleaning is performed.<br />\n",
    "\n",
    "For data cleaning,we consider either of these two methods (or both, too):\n",
    "1. **Removal:**<br />\n",
    "    Here we usually remove or delete those rows/columns, where we find the vulnerabilities.<br />\n",
    "    These rows/columns might include NAs.<br /><br />\n",
    "2. **Replacement/Filling:**<br />\n",
    "    Here we replace the NAs or incorrect or blanks data values with some acceptable value.<br />\n",
    "    Mostly, values are replaced by Mean or Mode values, so that the overall statistical structure may remain the same.<br />\n",
    "    Sometimes, we also fill them on the basis of some specific calculations.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What will we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have the time-series dataset populated with discrete data values, storing the total count of the total people (having COVID-19 confirmed, have died due to COVID-19 or have recovered from COVID-19), the issues:\n",
    "> 1. <u>can NOT be resolved by MEAN</u><br />\n",
    ">     because in our case, either the Data value can remain CONSTANT or can INCREASE, on every next day.<br />\n",
    ">     the MEAN need not to be discrete<br />\n",
    ">     MEAN can also be less than the previous data, for any particular day etc..<br /><br />\n",
    "> 2. <u>can NOT be resolved by MODE</u><br />\n",
    ">     because it's a medical data and hence any most often occurring number cannot be blindly replaced with a missing value etc..<br />\n",
    "\n",
    "Hence, we'll **NOT** be using any of the **replacement of MEAN/MODE/MEDIAN** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>We'll replace with maximum values</u>\n",
    "\n",
    "We will be replacing the missing values or NAs with the maximum value up to a day before the current day.<br />\n",
    "It means that - the values are carried constant for the next day whose data is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nrow(check.Confirmed): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in nrow(check.Confirmed): object 'check.Confirmed' not found\nTraceback:\n",
      "1. nrow(check.Confirmed)"
     ]
    }
   ],
   "source": [
    "# removing NAs, replacing incorrect values\n",
    "\n",
    "for (i in 1:nrow(check.Confirmed)) {\n",
    "  for (j in 5:ncol(check.Confirmed)) {\n",
    "    if(j==5) {\n",
    "      check.Confirmed[i,j] = ifelse(is.na(check.Confirmed[i, j]), 0, check.Confirmed[i,j])\n",
    "    } else {\n",
    "      if(is.na(check.Confirmed[i, j])){\n",
    "        check.Confirmed[i,j] = check.Confirmed[i, (j-1)]\n",
    "      } else if(check.Confirmed[i, (j-1)] > check.Confirmed[i, j]){\n",
    "        check.Confirmed[i,j] = check.Confirmed[i, (j-1)]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "for (i in 1:nrow(check.Deaths)) {\n",
    "  for (j in 5:ncol(check.Deaths)) {\n",
    "    if(j==5) {\n",
    "      check.Deaths[i,j] = ifelse(is.na(check.Deaths[i, j]), 0, check.Deaths[i,j])\n",
    "    } else {\n",
    "      if(is.na(check.Deaths[i, j])){\n",
    "        check.Deaths[i,j] = check.Deaths[i, (j-1)]\n",
    "      } else if(check.Deaths[i, (j-1)] > check.Deaths[i, j]){\n",
    "        check.Deaths[i,j] = check.Deaths[i, (j-1)]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "for (i in 1:nrow(check.Recovered)) {\n",
    "  for (j in 5:ncol(check.Recovered)) {\n",
    "    if(j==5) {\n",
    "      check.Recovered[i,j] = ifelse(is.na(check.Recovered[i, j]), 0, check.Recovered[i,j])\n",
    "    } else {\n",
    "      if(is.na(check.Recovered[i, j])){\n",
    "        check.Recovered[i,j] = check.Recovered[i, (j-1)]\n",
    "      } else if(check.Recovered[i, (j-1)] > check.Recovered[i, j]){\n",
    "        check.Recovered[i,j] = check.Recovered[i, (j-1)]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# replace blanks and incorrect country/state names\n",
    "\n",
    "# replacing in states\n",
    "states = as.character(check.Confirmed$Province.State)\n",
    "states.levels = as.character(levels(check.Confirmed$Province.State))\n",
    "\n",
    "states[states %in% \"\"] = \"Others\"\n",
    "states.levels[states.levels %in% \"\"] = \"Others\"\n",
    "\n",
    "\n",
    "#######\n",
    "states[states %in% \"From Diamond Princess\"] = \"Diamond Princess\"\n",
    "states.levels = states.levels[!states.levels %in% \"From Diamond Princess\"]\n",
    "\n",
    "\n",
    "# replacing in countries\n",
    "countries = as.character(check.Confirmed$Country.Region)\n",
    "countries.levels = as.character(levels(check.Confirmed$Country.Region))\n",
    "\n",
    "countries[countries %in% \"US\"] = \"United States\"\n",
    "countries[countries %in% \"UK\"] = \"United Kingdom\"\n",
    "countries[countries %in% \"Taiwan*\"] = \"Taiwan\"\n",
    "countries[countries %in% \"The Bahamas\"] = \"Bahamas\"\n",
    "countries[countries %in% \"Gambia, The\"] = \"Gambia\"\n",
    "countries[countries %in% \"Korea, South\"] = \"South Korea\"\n",
    "countries[countries %in% c(\"Congo (Brazzaville)\", \"Congo (Kinshasa)\", \"Republic of the Congo\")] = \"Democratic Republic of the Congo\"\n",
    "###\n",
    "countries.levels[countries.levels %in% \"US\"] = \"United States\"\n",
    "countries.levels[countries.levels %in% \"UK\"] = \"United Kingdom\"\n",
    "countries.levels[countries.levels %in% \"Taiwan*\"] = \"Taiwan\"\n",
    "countries.levels[countries.levels %in% \"The Bahamas\"] = \"Bahamas\"\n",
    "countries.levels[countries.levels %in% \"Gambia, The\"] = \"Gambia\"\n",
    "countries.levels[countries.levels %in% \"Korea, South\"] = \"South Korea\"\n",
    "\n",
    "countries.levels = countries.levels[!countries.levels %in% c(\"Congo (Brazzaville)\", \"Congo (Kinshasa)\", \"Republic of the Congo\")]\n",
    "countries.levels = c(countries.levels, \"Democratic Republic of the Congo\")\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in factor(c(states), levels = c(states.levels)): object 'states' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in factor(c(states), levels = c(states.levels)): object 'states' not found\nTraceback:\n",
      "1. factor(c(states), levels = c(states.levels))"
     ]
    }
   ],
   "source": [
    "# rectified fectors\n",
    "states.factor  = factor(c(states), levels = c(states.levels))\n",
    "countries.factor  = factor(countries, levels = countries.levels)\n",
    "\n",
    "\n",
    "## CUZ' INITIAL 4 COLUMNS ARE COMMON IN ALL 3 DATASETS ##\n",
    "\n",
    "# editing factors in datasets\n",
    "check.Confirmed = cbind(\n",
    "                    Province.State = states.factor,\n",
    "                    Country.Region = countries.factor,\n",
    "                    check.Confirmed[,3:ncol(check.Confirmed)]\n",
    "                  )\n",
    "\n",
    "check.Deaths = cbind(\n",
    "                    Province.State = states.factor,\n",
    "                    Country.Region = countries.factor,\n",
    "                    check.Deaths[,3:ncol(check.Deaths)]\n",
    "                  )\n",
    "\n",
    "check.Recovered = cbind(\n",
    "                    Province.State = states.factor,\n",
    "                    Country.Region = countries.factor,\n",
    "                    check.Recovered[,3:ncol(check.Recovered)]\n",
    "                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now our data has been cleaned.** Viewing the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# sample NA val\n",
    "check.Confirmed[which(str_detect(check.Confirmed$Country.Region, \"Cruise Ship\")),]\n",
    "\n",
    "# sample wrong data \"french guiana\"\n",
    "check.Confirmed[which(str_detect(check.Confirmed$Province.State, \"French Guiana\")),]\n",
    "\n",
    "# sample blank data ---> State (replaced by 'Other')\n",
    "head(check.Recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "#### * Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we have cleaned the dataset, yet we see that **'Diamond Princess'** Cruise is still therein among the countries' data.<br />\n",
    "Hence it's an outlier, and hence has to be separated.\n",
    "\n",
    "**So, now we'll start the process of data reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# removing diamond princess\n",
    "Diamond.Princess.Confirmed = check.Confirmed[ which(str_detect(check.Confirmed$Country.Region, \"Cruise Ship\", negate = F)), ]\n",
    "check.Confirmed = check.Confirmed[ which(str_detect(check.Confirmed$Country.Region, \"Cruise Ship\", negate = T)), ]\n",
    "\n",
    "Diamond.Princess.Deaths = check.Deaths[ which(str_detect(check.Deaths$Country.Region, \"Cruise Ship\", negate = F)),]\n",
    "check.Deaths = check.Deaths[ which(str_detect(check.Deaths$Country.Region, \"Cruise Ship\", negate = T)), ]\n",
    "\n",
    "Diamond.Princess.Recovered = check.Recovered[ which(str_detect(check.Recovered$Country.Region, \"Cruise Ship\", negate = F)), ]\n",
    "check.Recovered = check.Recovered[ which(str_detect(check.Recovered$Country.Region, \"Cruise Ship\", negate = T)), ]\n",
    "\n",
    "## Rectifying Row sequences\n",
    "row.names(check.Confirmed) <- NULL\n",
    "row.names(check.Deaths) <- NULL\n",
    "row.names(check.Recovered) <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verifying if it is removed or not:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Let's check whether Diamond Princess is still at row 166 or not\n",
    "check.Confirmed[166,]\n",
    "#check.Deaths[166,]\n",
    "#check.Recovered[166,]\n",
    "\n",
    "\n",
    "# also checking dimention\n",
    "cat(\"\\nEarlier dimention: 468 X 62\\n\\n\")    # as we saw initially\n",
    "\n",
    "cat(\"New dimention: \", dim(check.Confirmed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**OK! so it's gone!**_\n",
    "<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the dataset that hold the counts of the COVID-19 cases of different geographical locations.<br />\n",
    "Hence, we can now create a dataset to generate the map for every unique day.(that we saw early in this project)<br /><br />\n",
    "\n",
    "* It means, we want to <u>plot all the countries/regions</u> that are affected on a particular day\n",
    "* It gives us an idea that - among all the given countries, <u>either we are going to plot a selected country on world-map, or not</u>, for a specific day\n",
    "* the **factor** on which basis we'll be deciding is - <u>whether country has any confirmed case</u> till that day <u>or not</u>\n",
    "\n",
    "* So, We'd also **need** the _Latitude and Longitude_ position for those country\n",
    "<br /><br />\n",
    "\n",
    "Finally, we can roughly estimate that we can have only 2 choices for any region, say **0** & **1**, such that:\n",
    "> **0**:  don't plot on map, if it has no confirm cases i.e. val for total confirm case on that day are 0 <br />\n",
    "> **1**:  plot on map, if it has some confirm cases i.e. there is at least 1 confirm case on that day <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "<font size=\"3\">\n",
    "    Therefor, We're going to use **Unit Scaling** to set all the values from <u>5th to last column</u>\n",
    "</font>\n",
    "<br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in UNIT SCALING, all the data has either 0 or 1 value\n",
    "\n",
    "ever.Affected = check.Confirmed\n",
    "\n",
    "# Unit scaling\n",
    "for (i in row.names(ever.Affected)) {\n",
    "  for (j in 5:ncol(ever.Affected)) {\n",
    "    if(ever.Affected[i,j] != 0)\n",
    "      ever.Affected[i,j] = 1\n",
    "  }\n",
    "}\n",
    "\n",
    "head(ever.Affected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /><br />\n",
    "\n",
    "#### Next step is to find and remove the outliers:\n",
    "\n",
    "We'll use **scatter plots** & **box plots** to _identify_ and **compare the MEAN** of every day to _verify_ these outliers, so that we can remove them, successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(check.Confirmed): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(check.Confirmed): object 'check.Confirmed' not found\nTraceback:\n",
      "1. ggplot(check.Confirmed)"
     ]
    }
   ],
   "source": [
    "# Let's visualize our data to varify:\n",
    "library(ggplot2)\n",
    "\n",
    "options(repr.plot.width=14, repr.plot.height=8)\n",
    "ggplot(check.Confirmed) +\n",
    "  geom_point(aes(x=check.Confirmed$Province.State, y=check.Confirmed$X1.29.20), color=\"red\", size=2) +\n",
    "  theme(\n",
    "          text = element_text(family = \"Gill Sans\")\n",
    "          ,plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5)\n",
    "          ,plot.subtitle = element_text(size = 25, family = \"Courier\", face = \"bold\", hjust = 0.5)\n",
    "          ,axis.text = element_text(size = 12)\n",
    "          ,axis.title = element_text(size = 20)\n",
    "          ,axis.text.x = element_blank()\n",
    "  )\n",
    "\n",
    "cat(\"\\n\\n\")\n",
    "\n",
    "#ggplot(check.Deaths) +\n",
    "#  geom_point(aes(x=check.Deaths$Province.State, y=check.Deaths$X1.29.20), color=\"red\", size=2)#\n",
    "\n",
    "#ggplot(check.Recovered) +\n",
    "#  geom_point(aes(x=check.Recovered$Province.State, y=check.Recovered$X1.29.20), color=\"red\", size=2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Let's find the name of this outlier:-\n",
    "\n",
    "check.Confirmed[which(check.Confirmed$X1.29.20 > 400), c(\"Province.State\", \"Country.Region\")]\n",
    "#check.Deaths[which(check.Deaths$X1.29.20 > 15), c(\"Province.State\", \"Country.Region\")]\n",
    "#check.Recovered[which(check.Recovered$X1.29.20 > 20), c(\"Province.State\", \"Country.Region\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "So, it's **Hubei**.<br />\n",
    "We'll verify it by comparison of mean value on daily basis, <u>including and excluding the Hubei province</u>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in apply(check.Confirmed[, 5:ncol(check.Confirmed)], 2, mean): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in apply(check.Confirmed[, 5:ncol(check.Confirmed)], 2, mean): object 'check.Confirmed' not found\nTraceback:\n",
      "1. apply(check.Confirmed[, 5:ncol(check.Confirmed)], 2, mean)"
     ]
    }
   ],
   "source": [
    "# Here we are trying to compare the mean values of everyday, including and excluding Hubei province\n",
    "With.Hubei = as.numeric(apply(check.Confirmed[,5:ncol(check.Confirmed)], 2, mean))\n",
    "\n",
    "exceptHubei = check.Confirmed[ which(str_detect(check.Confirmed$Province.State, \"Hubei\", negate = T)), ]\n",
    "Without.Hubei = as.numeric(apply(exceptHubei[,5:ncol(exceptHubei)], 2, mean))\n",
    "\n",
    "# creating a dataframe for comperision\n",
    "Mean.Comparision.Table = data.frame(\n",
    "              \"Date\" = as.character(colnames(check.Confirmed)[5:ncol(check.Confirmed)]),\n",
    "              \"With Hubei\" = c(With.Hubei),\n",
    "              \"Without Hubei\" = c(Without.Hubei))\n",
    "\n",
    "tail(Mean.Comparision.Table, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "So it's clear that the Hubei is the outlier..<br />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# let's remove Hubei from our dataset:\n",
    "Hubei.Confirmed = check.Confirmed[ which(str_detect(check.Confirmed$Province.State, \"Hubei\", negate = F)), ]\n",
    "check.Confirmed = check.Confirmed[ which(str_detect(check.Confirmed$Province.State, \"Hubei\", negate = T)), ]\n",
    "\n",
    "Hubei.Deaths = check.Deaths[ which(str_detect(check.Deaths$Province.State, \"Hubei\", negate = F)),]\n",
    "check.Deaths = check.Deaths[ which(str_detect(check.Deaths$Province.State, \"Hubei\", negate = T)), ]\n",
    "\n",
    "Hubei.Recovered = check.Recovered[ which(str_detect(check.Recovered$Province.State, \"Hubei\", negate = F)), ]\n",
    "check.Recovered = check.Recovered[ which(str_detect(check.Recovered$Province.State, \"Hubei\", negate = T)), ]\n",
    "\n",
    "\n",
    "## Rectifying Row sequences\n",
    "row.names(check.Confirmed) <- NULL\n",
    "row.names(check.Deaths) <- NULL\n",
    "row.names(check.Recovered) <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'Hubei.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'Hubei.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "Hubei.Confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Earlier dimention: 467 X 62\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in cat(\"New dimention: \", dim(check.Confirmed)): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in cat(\"New dimention: \", dim(check.Confirmed)): object 'check.Confirmed' not found\nTraceback:\n",
      "1. cat(\"New dimention: \", dim(check.Confirmed))"
     ]
    }
   ],
   "source": [
    "# Let's check the once dimention more\n",
    "\n",
    "# also checking dimention\n",
    "cat(\"\\nEarlier dimention: 467 X 62\\n\\n\")    # after removing Cruis Ship\n",
    "\n",
    "cat(\"New dimention: \", dim(check.Confirmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(check.Confirmed): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(check.Confirmed): object 'check.Confirmed' not found\nTraceback:\n",
      "1. ggplot(check.Confirmed)"
     ]
    }
   ],
   "source": [
    "# Let's visualize once more\n",
    "library(ggplot2)\n",
    "\n",
    "options(repr.plot.width=14, repr.plot.height=8)\n",
    "ggplot(check.Confirmed) +\n",
    "  geom_point(aes(x=check.Confirmed$Province.State, y=check.Confirmed$X1.29.20), color=\"red\", size=2) +\n",
    "  theme(\n",
    "          text = element_text(family = \"Gill Sans\")\n",
    "          ,plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5)\n",
    "          ,plot.subtitle = element_text(size = 25, family = \"Courier\", face = \"bold\", hjust = 0.5)\n",
    "          ,axis.text = element_text(size = 12)\n",
    "          ,axis.title = element_text(size = 20)\n",
    "          ,axis.text.x = element_blank()\n",
    "  )\n",
    "\n",
    "cat(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "Although now it's comparatively better, still have some outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'check.Confirmed' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Let's find them out, too:-\n",
    "check.Confirmed[which(check.Confirmed$X1.29.20 > 100), c(\"Province.State\", \"Country.Region\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in apply(check.Confirmed[, 5:ncol(check.Confirmed)], 2, mean): object 'check.Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in apply(check.Confirmed[, 5:ncol(check.Confirmed)], 2, mean): object 'check.Confirmed' not found\nTraceback:\n",
      "1. apply(check.Confirmed[, 5:ncol(check.Confirmed)], 2, mean)"
     ]
    }
   ],
   "source": [
    "# Checking for mean comperision\n",
    "With.China = as.numeric(apply(check.Confirmed[,5:ncol(check.Confirmed)], 2, mean))\n",
    "\n",
    "exceptChina = check.Confirmed[ which(str_detect(check.Confirmed$Country.Region, \"China\", negate = T)), ]\n",
    "Without.China = as.numeric(apply(exceptChina[,5:ncol(exceptChina)], 2, mean))\n",
    "\n",
    "# comperision\n",
    "Mean.Comparision.Table = data.frame(\n",
    "              \"Date\" = as.character(colnames(check.Confirmed)[5:ncol(check.Confirmed)]),\n",
    "              \"With China\" = c(With.China),\n",
    "              \"Without China\" = c(Without.China))\n",
    "\n",
    "head(Mean.Comparision.Table, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "So, while talking about the whole world, the complete mainland of China seems to be the outlier.\n",
    "Although, we'll have to verify it first.\n",
    "```\n",
    "<br /><br />\n",
    "<u>But because, it's not a single row, we will perform this action later i.e. during data-transformation.</u><br />\n",
    "\n",
    "<hr /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "“cannot open file 'Notebooks/syllabus/static/cleaned/time_series_19-covid-Confirmed.csv': No such file or directory”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.csv(\"Notebooks/syllabus/static/cleaned/time_series_19-covid-Confirmed.csv\")",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "# We've already saved the cleaned version of the all the files\n",
    "# Loading the files in order to transform the dataset(s)\n",
    "\n",
    "# loading raw data - from source\n",
    "Confirmed = read.csv(\"Notebooks/syllabus/static/cleaned/time_series_19-covid-Confirmed.csv\")\n",
    "Deaths = read.csv(\"Notebooks/syllabus/static/cleaned/time_series_19-covid-Deaths.csv\")\n",
    "Recovered = read.csv(\"Notebooks/syllabus/static/cleaned/time_series_19-covid-Recovered.csv\")\n",
    "\n",
    "Hubei.Confirmed = read.csv(\"Notebooks/syllabus/static/cleaned/Hubei/time_series_19-covid-Confirmed.csv\")\n",
    "Hubei.Deaths = read.csv(\"Notebooks/syllabus/static/cleaned/Hubei/time_series_19-covid-Deaths.csv\")\n",
    "Hubei.Recovered = read.csv(\"Notebooks/syllabus/static/cleaned/Hubei/time_series_19-covid-Recovered.csv\")\n",
    "\n",
    "Diamond.Princess.Confirmed = read.csv(\"Notebooks/syllabus/static/cleaned/Diamond-Princess/time_series_19-covid-Confirmed.csv\")\n",
    "Diamond.Princess.Deaths = read.csv(\"Notebooks/syllabus/static/cleaned/Diamond-Princess/time_series_19-covid-Deaths.csv\")\n",
    "Diamond.Princess.Recovered = read.csv(\"Notebooks/syllabus/static/cleaned/Diamond-Princess/time_series_19-covid-Recovered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in str(Hubei.Recovered): object 'Hubei.Recovered' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in str(Hubei.Recovered): object 'Hubei.Recovered' not found\nTraceback:\n",
      "1. str(Hubei.Recovered)"
     ]
    }
   ],
   "source": [
    "# as known, all of these files have same set of columns,\n",
    "# the only things that differ are data values in dates' columns\n",
    "\n",
    "# Let's see any one dataset's structure (as all are similer)\n",
    "str(Hubei.Recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "* Now, recalling the Problem Statement, we aim to find out the status of COVID-19 in China, within next 7 days\n",
    "* In order to do so, we need to analyze the status of COVID-19 on all the previous days\n",
    "</font> \n",
    "\n",
    "### What would it tell us?\n",
    "By this, we'd be capable enough to make an estimate by what RATE the Coronavirus is spreading since late January.<br /><br />\n",
    "Hence, we need to transform the data in order:\n",
    "> 1. such that rows hold every data <u>Country wise, instead of State wise</u>\n",
    "> 2. to include a <u>new column \"Date\"</u> to store aggregate data (of 3 datasets) in a single place\n",
    "> 3. <u>remove unnecessary columns</u> i.e. *States, Latitude & Longitude*\n",
    "\n",
    "#### Arranging data Country-Wise\n",
    "<br /> \n",
    "**Steps:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in tail(Confirmed): object 'Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in tail(Confirmed): object 'Confirmed' not found\nTraceback:\n",
      "1. tail(Confirmed)"
     ]
    }
   ],
   "source": [
    "# We need Countries' data:\n",
    "\n",
    "# It's because: many states have very few cases\n",
    "tail(Confirmed)\n",
    "\n",
    "# Most of the states' name is not identified\n",
    "unknown = nrow(Recovered[which(str_detect(Recovered$Province.State, \"Others\")),])\n",
    "cat(unknown, \"/\", nrow(Recovered), \" States are NOT identified\")\n",
    "\n",
    "# Ultimatly, any precaution/cure or action is more likely be taken onto the country level, rather than the individual state, as it's the case of a severe Epidemic\n",
    "# Only then it would be much easier for us to make any possible estimate for the world as well, due to not having really a huge data about each and every single state of the countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "As we know that Country column is a *Factor*, we <u>can easily list those countries'</u>, who have reported Confirmed cases (on the daily basis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in levels(Confirmed$Country.Region): object 'Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in levels(Confirmed$Country.Region): object 'Confirmed' not found\nTraceback:\n",
      "1. levels(Confirmed$Country.Region)"
     ]
    }
   ],
   "source": [
    "Countries = levels(Confirmed$Country.Region)\n",
    "\n",
    "cat(\"\\nTotal number of affected countries: \", nlevels(Confirmed$Country.Region), \"\\n\\n\\nCountries:\")\n",
    "head(as.matrix(Countries), 5) # top 5 countries (in sorted list-namewise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for extracting required data\n",
    "\n",
    "\n",
    "# finds the total cases reported in given country \n",
    "    # (by Adding all the data of different states in it)\n",
    "country.aggregate.daily  <-  function(dfName, country) {\n",
    "  \n",
    "  df <- get(dfName)\n",
    "  df = df[which(str_detect(df$Country.Region, country)),]\n",
    "  df = cbind(States = df[,1], Country = df[,2], df[,5:ncol(df)])     # ELEMINATING LATITUDE/LONGITUDE Col.\n",
    "  \n",
    "  row.names(df) <- NULL    \n",
    "    \n",
    "  temp = df                                             # all states' data of a country\n",
    "  df = temp[1,] \n",
    "  \n",
    "  df[3:ncol(temp)] = apply(   temp[,3:ncol(temp)],\n",
    "                            2,\n",
    "                            sum\n",
    "                        )                               # applying sum of all the states' values\n",
    "  df = df[2:ncol(df)]                                   # removing column 'States'  \n",
    "  row.names(df) <- NULL  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# generated a dataframe having required data arranged Country-Wise \n",
    "    # (by appending every single country's data)\n",
    "countries.daily <-  function(dfName, cList) {\n",
    "  \n",
    "  n = length(cList)       # number of countries\n",
    "  \n",
    "  flag = 0\n",
    "  \n",
    "  for (i in cList) {\n",
    "    \n",
    "    if(flag == 0) {\n",
    "      df = country.aggregate.daily(dfName, i)\n",
    "      flag = 1\n",
    "    } else {\n",
    "      temp = country.aggregate.daily(dfName, i)\n",
    "      df = rbind(df, temp)\n",
    "    }    \n",
    "  }\n",
    "  \n",
    "  row.names(df) <- NULL  \n",
    "  return(df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in get(dfName): object 'Confirmed' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in get(dfName): object 'Confirmed' not found\nTraceback:\n",
      "1. country.aggregate.daily(\"Confirmed\", \"China\")",
      "2. get(dfName)   # at line 8 of file <text>"
     ]
    }
   ],
   "source": [
    "China.Confirmed = country.aggregate.daily(\"Confirmed\", \"China\")\n",
    "World.Confirmed = countries.daily(\"Confirmed\", Countries)\n",
    "\n",
    "China.Confirmed\n",
    "cat(\"\\n\\n\")\n",
    "head(World.Confirmed)\n",
    "\n",
    "China.Deaths = country.aggregate.daily(\"Deaths\", \"China\")\n",
    "World.Deaths = countries.daily(\"Deaths\", Countries)\n",
    "China.Recovered = country.aggregate.daily(\"Recovered\", \"China\")\n",
    "World.Recovered = countries.daily(\"Recovered\", Countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "### Moving to next step\n",
    "\n",
    "#### We need datewise data:\n",
    "\n",
    "* It's so because, we aim to analyze data on the daily basis\n",
    ">  Hence we'd have to add another column \"Date\" or simply \"Day\" (to hold day-> 1, 2...)\n",
    "\n",
    "* in order to do so, we'd have to transform our data into Cross-sectional (China, Hubei & Diamond Princess) or Pooled data (Countries of world other than China)\n",
    "\n",
    "<br /> \n",
    "#### Let's understand what a <u>Cross-sectional</u> & a <u>Pooled data</u> is:-\n",
    "> * **Cross-sectional data:** Data of one or more variables, collected at the same point in time. <br />\n",
    "> * **Pooled data:** A combination of time series data and cross-sectional data.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "countries.daily.bulk.summary = function(cList) { # date wise country data\n",
    "  \n",
    "  # structure of resulting dataset (initially blank)\n",
    "  df <- data.frame(\n",
    "    Country = NULL,\n",
    "    Day = NULL,           # day no.\n",
    "    Date = NULL,\n",
    "    Confirmed = NULL,\n",
    "    Deaths = NULL,\n",
    "    Recovered = NULL\n",
    "  )\n",
    "  \n",
    "  # calculating all countries' data (date wise) through iteration\n",
    "  for(i in cList) {\n",
    "    this.one.confirmed = country.aggregate.daily(\"Confirmed\", i)\n",
    "    this.one.deaths = country.aggregate.daily(\"Deaths\", i)\n",
    "    this.one.recovered = country.aggregate.daily(\"Recovered\", i)\n",
    "    \n",
    "    times = ncol(this.one.confirmed)-1      # no. of days\n",
    "    day = 1:times\n",
    "    d = as.Date(\"21-01-2020\", format(c(\"%d-%m-%Y\")))\n",
    "    \n",
    "    date = as.character((day + d), format(c(\"%d-%m-%Y\")))      # its lenngth is equal to --> no. of days\n",
    "    date = factor(c(date), levels = date)\n",
    "    \n",
    "    #max(Deaths.temp[1,5:ncol(Deaths.temp)])\n",
    "    confirmed = as.numeric(this.one.confirmed[1,2:ncol(this.one.confirmed)])\n",
    "    \n",
    "    deaths = as.numeric(this.one.deaths[1,2:ncol(this.one.deaths)])\n",
    "    \n",
    "    recovered = as.numeric(this.one.recovered[1,2:ncol(this.one.recovered)])\n",
    "    \n",
    "    dataset <- data.frame(\n",
    "      Country = rep(i, times),\n",
    "      Day = factor(c(1:length(date)), levels = 1:length(date)),\n",
    "      Date = date,\n",
    "      Confirmed = confirmed,\n",
    "      Deaths = deaths,\n",
    "      Recovered = recovered\n",
    "    )\n",
    "    \n",
    "    # joining this country\n",
    "    df = rbind(df, dataset)\n",
    "  }\n",
    "    \n",
    "  return(df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in countries.daily.bulk.summary(Countries): could not find function \"countries.daily.bulk.summary\"\n",
     "output_type": "error",
     "traceback": [
      "Error in countries.daily.bulk.summary(Countries): could not find function \"countries.daily.bulk.summary\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "bulk = countries.daily.bulk.summary(Countries)\n",
    "head(bulk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> <br /> \n",
    "<font size=\"3\">\n",
    "<u>For better analysis, let's add 2 more columns:</u>\n",
    "> **1. Closed.Cases** = consists all cases, that are Expired or Recovered<br />\n",
    "> **2. Active.Cases** = cases that are neither Expired nor Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'bulk' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'bulk' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "bulk$Active.Cases = bulk$Confirmed - (bulk$Deaths + bulk$Recovered)\n",
    "bulk$Closed.Cases = bulk$Deaths + bulk$Recovered\n",
    "tail(bulk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "<font size=\"3\">\n",
    "So, our Pooled dataset ready.<br /><br />\n",
    "<u>Let's understand this dataset</u>:-\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in str(bulk): object 'bulk' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in str(bulk): object 'bulk' not found\nTraceback:\n",
      "1. str(bulk)"
     ]
    }
   ],
   "source": [
    "# Analysing the Pooled data\n",
    "str(bulk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Pooled Datasets (bulk & four)\n",
    "<br /> \n",
    " \\* <u>Pooled data is a combination of time series data and cross-sectional data</u> <br /><br />\n",
    " \n",
    " \n",
    "   Number of columns: 8 <br /> \n",
    "   Here we are discussing about the _**Bulk** dataset_\n",
    "   \n",
    "> #### Country:\n",
    "   > * Datatype: **Factor** with 153-levels <br /> \n",
    "   > * Holds the name of Countries for daily data<br /> \n",
    "   > * Eg.: Japan\n",
    ">\n",
    "> #### Day:\n",
    "   > * Datatype: **Factor** with 58-levels <br /> \n",
    "   > * Holds days numbered from 1 upto the last day <br /> \n",
    "   > * Eg.: for Jan 22<sup>nd</sup>, Day is 1, Jan 23<sup>rd</sup>, Day is 2 and so on..\n",
    ">\n",
    "> #### Date:\n",
    "   > * Datatype: **Factor** with 58-levels <br /> \n",
    "   > * Holds dates in format **dd-mm-yyyy** and where individual level has the datatype _Date_ <br /> \n",
    "   > * Eg.: 22-01-2020\n",
    ">\n",
    "> #### Confirmed:\n",
    "   > * Datatype: **num** <br /> \n",
    "   > * Holds total number of confirm cases in a country, upto the given date/day <br /> \n",
    "   > * Eg.: upto 01-02-2020, Japan reported\t20 COVID-19 cases\n",
    ">\n",
    "> #### Deaths:\n",
    "   > * Datatype: **num** <br /> \n",
    "   > * Holds total number of deaths in a country, upto the given date/day <br /> \n",
    "   > * Eg.: upto 01-02-2020, Japan reported\tno Deaths\n",
    ">\n",
    "> #### Recovered:\n",
    "   > * Datatype: **num** <br /> \n",
    "   > * Holds total number of recoveries in a county, upto the given date/day <br /> \n",
    "   > * Eg.: upto 01-02-2020, Japan reported\t1 Recoveries\n",
    ">\n",
    "> #### Active.Cases:\n",
    "   > * Datatype: **num** <br /> \n",
    "   > * Holds total Confirmed cases, except Deaths & Recoveries in a country, upto the given date/day <br /> \n",
    "   > * Eg.: upto 01-02-2020, Japan had 19 Active cases\n",
    ">\n",
    "> #### Closed.Cases:\n",
    "   > * Datatype: **num** <br /> \n",
    "   > * Holds total number of Recoveries or Deaths in a country, upto the given date/day <br /> \n",
    "   > * Eg.: upto 01-02-2020, Japan had closed 1 COVID-19 case\n",
    "   \n",
    "   \n",
    "#### Now we are all set to filter out China from this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'bulk' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'bulk' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# filtering out the China\n",
    "China.dataset = bulk[which(str_detect(bulk$Country, 'China')),]\n",
    "\n",
    "# World Pooled dataset (except china)\n",
    "bulk = bulk[which(str_detect(bulk$Country, 'China', negate=T)),] # updating bulk itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in head(China.dataset): object 'China.dataset' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in head(China.dataset): object 'China.dataset' not found\nTraceback:\n",
      "1. head(China.dataset)"
     ]
    }
   ],
   "source": [
    "head(China.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "<font size=\"3\">\n",
    "In the same manner, we create <u>two</u> datasets\n",
    "* holds <u>**all** the data of all the countries except Hubei in China</u>\n",
    "* holds whole data categorized into <u>four locations</u>.\n",
    "<br /><br /> \n",
    "These four locations are:\n",
    "> 1. Diamond Princess \n",
    "> 2. Hubei province (alone) same as Diamond Princess Cruise Ship\n",
    "> 3. China alone data (Except Hubei province)\n",
    "> 4. World (Except China), collectively\n",
    "    \n",
    "<br />\n",
    "    \n",
    "The 2<sup>nd</sup> type of dataset is very necessary because it consists of all the outliers as well...\n",
    "<br />\n",
    "* Actually, here we can take them into consideration because:\n",
    "> 1. Here we are comparing them with the whole World's data collectively\n",
    "> 2. It's that kind of MEDICAL Data, where outliers can not be ignored! In-fact this single country and that ship are spreading the disease, rapidly.\n",
    "> 3. This 2nd dataset alone keeps track on the whole data, reported till the last date\n",
    "</font>\n",
    "\n",
    "<hr />\n",
    "* We've already saved this dataset\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in file(file, \"rt\"):\n",
      "“cannot open file 'Notebooks/syllabus/static/pooled/countryWise_bulk_summary.csv': No such file or directory”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.csv(\"Notebooks/syllabus/static/pooled/countryWise_bulk_summary.csv\")",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "## Load both datewise-datasets (world & FOUR)\n",
    "# includes data of all the countries\n",
    "all = read.csv('Notebooks/syllabus/static/pooled/countryWise_bulk_summary.csv')\n",
    "\n",
    "# includes data of four majour location\n",
    "four = read.csv('Notebooks/syllabus/static/pooled/Four_dataset_locationWise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function (..., na.rm = FALSE)  \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in str(four): object 'four' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in str(four): object 'four' not found\nTraceback:\n",
      "1. str(four)"
     ]
    }
   ],
   "source": [
    "str(all)\n",
    "\n",
    "cat(\"\\n\\n\")\n",
    "\n",
    "str(four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> <br /> \n",
    "In the __*all dataset*__, everything is same as in 'Bulk' dataset <br />\n",
    "\n",
    "In the __*four dataset*__: <br />\n",
    "\n",
    "> #### Location:\n",
    "   > * Datatype: **Factor** with 4-levels <br /> \n",
    "   > * Holds the name of Locations (as Countries in 'Bulk') for daily data <br /> \n",
    "   > * Levels: World, China, Hubei & Diamond Princess <br /> <br />\n",
    "Rest **7** columns are same as those of 'Bulk' dataset\n",
    "\n",
    "\n",
    "### Let's analyze that how China differ from rest of the data using Boxplots\n",
    "#### Why Boxplot:-  <br /> \n",
    "> * It's a single visualization that tells about many statistical quantifiers <br />\n",
    "> <img src=\"../pics/boxplot.png\" height=\"50%\" width=\"50%\" alt=\"Boxplot explained\"/> <br />\n",
    "> * It's very easy to detect Outliers through boxplot <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(four, aes(x = Day, y = Confirmed, color = Day)): could not find function \"ggplot\"\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(four, aes(x = Day, y = Confirmed, color = Day)): could not find function \"ggplot\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Initially we plot dataset with majour Locations\n",
    "options(repr.plot.width=16, repr.plot.height=8)\n",
    "withChina<-ggplot(four, aes(x=Day, y=Confirmed, color=Day)) +\n",
    "  geom_boxplot(aes(group=Day)) +\n",
    "  labs(title=\"Including China\") +\n",
    "  theme_classic() +\n",
    "  theme(\n",
    "          text = element_text(family = \"Gill Sans\")\n",
    "          ,plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5)\n",
    "          ,plot.subtitle = element_text(size = 25, family = \"Courier\", face = \"bold\", hjust = 0.5)\n",
    "          ,axis.text = element_text(size = 12)\n",
    "          ,axis.title = element_text(size = 20)\n",
    "  )\n",
    "\n",
    "cat(\"\\n\\n\")\n",
    "withChina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /><br /> \n",
    "<font size=\"3\">\n",
    "Here we get a <u>continuous sequence of **outliers**</u>, for roughly upto 45 days<br />\n",
    "Now, as per our previous analysis (through word-clouds and mean-comparison, we assumed the China as this outlier)<br /><br /> \n",
    "In order to Test our hypothesis, let's plot China alone, as well as Rest of all data except China\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(four[which(str_detect(four$Location, \"China\", negate = F)), : could not find function \"ggplot\"\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(four[which(str_detect(four$Location, \"China\", negate = F)), : could not find function \"ggplot\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "options(repr.plot.width=16, repr.plot.height=8)\n",
    "\n",
    "chinaAlone <- ggplot(four[which(str_detect(four$Location, \"China\", negate=F)),], aes(x=Day, y=Confirmed, color=Day)) +\n",
    "  geom_point(aes(group=Day)) +\n",
    "  labs(title=\"Only China\") +\n",
    "  theme_classic() +\n",
    "  theme(\n",
    "          text = element_text(family = \"Gill Sans\")\n",
    "          ,plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5)\n",
    "          ,plot.subtitle = element_text(size = 25, family = \"Courier\", face = \"bold\", hjust = 0.5)\n",
    "          ,axis.text = element_text(size = 12)\n",
    "          ,axis.title = element_text(size = 20)\n",
    "  )\n",
    "\n",
    "withoutChina <- ggplot(four[which(str_detect(four$Location, \"China\", negate=T)),], aes(x=Day, y=Confirmed, color=Day)) +\n",
    "  geom_boxplot(aes(group=Day)) +\n",
    "  labs(title=\"Excluding China\") +\n",
    "  theme_classic() +\n",
    "  theme(\n",
    "          text = element_text(family = \"Gill Sans\")\n",
    "          ,plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5)\n",
    "          ,plot.subtitle = element_text(size = 25, family = \"Courier\", face = \"bold\", hjust = 0.5)\n",
    "          ,axis.text = element_text(size = 12)\n",
    "          ,axis.title = element_text(size = 20)\n",
    "  )\n",
    "\n",
    "cat(\"\\n\\n\")\n",
    "chinaAlone\n",
    "cat(\"\\n\\n\")\n",
    "withoutChina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /> \n",
    "#### Comparing above 2 plots with our previous single plot of the whole (4) data categorize, collectively:-\n",
    "<font size=\"3\"> \n",
    "1. First box plots resembles the sequence, that is far more similar to the Outliers' sequence\n",
    "2. Along with this, when we try plotting the whole data again, after removing the China, we find that there is no outlier, at all\n",
    "<br /> \n",
    "    \n",
    "So, finally we can say that the **China is an outlier**, and hence we'll study China, separately!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   \n",
       "1 .Primitive(\"all\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in head(four): object 'four' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in head(four): object 'four' not found\nTraceback:\n",
      "1. head(four)"
     ]
    }
   ],
   "source": [
    "# Let's view few of the rows in existing datasets\n",
    "head(all)\n",
    "head(four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr /> <br /> \n",
    "Now, as we aim to analyze the status of COVID-19 within next 10 days, which means that we basically want to analyze the active or closed cases within that time duration.<br /><br />\n",
    "But, as these 2 are just discrete figures and hence can vary depending upon the Confirmed, Recovery & Death cases<br />\n",
    "It means all these figures can vary dynamically\n",
    "<br /><br /> \n",
    "So, in this situation, finding any internal relation between the columns Confirmed/Recovery/Death and Active/Closed cases ain't an easy task.<br />\n",
    "Now, in order to establish a relationship between these, the can take <u>**Rate of Increase** in Active/Closed cases</u>\n",
    "```\n",
    "i.e. what percent (%) of Confirmed cases are Active/Closed, and which would simply be depend upon total Confirmed cases\n",
    "```\n",
    "\n",
    "<br /> \n",
    "<font size=\"3\">\n",
    "<u>Hence, before we move towards creating a suitable model for our problem form available dataset, we'd have to do one last transformation, by adding two more columns to our existing dataset i.e.</u>\n",
    "    1. Active Cases(%)\n",
    "    2. Closed Cases(%)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percent (using Confirmed cases as total)\n",
    "percent <- function(dfName){\n",
    "    get(dfName) -> df\n",
    "    part <- NULL\n",
    "    \n",
    "    for(i in 1:nrow(df)) {\n",
    "        val = df[i,\"Active.Cases\"]\n",
    "        Total = df[i,\"Confirmed\"]\n",
    "        \n",
    "        \n",
    "        if(i == 1)\n",
    "            if(val==0)\n",
    "                part = 0\n",
    "            else\n",
    "                part = as.numeric((val*100)/Total)\n",
    "        else\n",
    "            if(val==0)\n",
    "                part = c(part, 0)\n",
    "            else\n",
    "                part <- c(part, as.numeric((val*100)/Total))\n",
    "    }\n",
    "        \n",
    "    return(part)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in get(dfName): object 'four' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in get(dfName): object 'four' not found\nTraceback:\n",
      "1. percent(\"four\")",
      "2. get(dfName)   # at line 3 of file <text>"
     ]
    }
   ],
   "source": [
    "# CASES -> percentage\n",
    "four$'percent_active' = percent(\"four\")     # Active cases, out of every 100 Confirmed cases\n",
    "four$'percent_closed' = 100-percent(\"four\") # Closed cases, out of every 100 Confirmed cases\n",
    "\n",
    "\n",
    "all$'percent_active' = percent(\"all\")     # Active cases, out of every 100 Confirmed cases\n",
    "all$'percent_closed' = 100-percent(\"all\") # Closed cases, out of every 100 Confirmed cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function (..., na.rm = FALSE)  \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in str(four): object 'four' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in str(four): object 'four' not found\nTraceback:\n",
      "1. str(four)"
     ]
    }
   ],
   "source": [
    "# Look onto the structure whether the things are updated or not\n",
    "str(all)\n",
    "\n",
    "cat(\"\\n\\n\")\n",
    "\n",
    "str(four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *OK! Everything is set. Now we can go for themodel creation...*\n",
    "\n",
    "<br /><hr /><br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
