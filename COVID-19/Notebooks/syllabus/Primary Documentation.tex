\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Primary Documentation}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    A Predictive Data Analysis \textasciitilde{} 19-nCoV

(Data-Science cum Data-Mining project in R)

 -Ravi Prakash

    This section includes:

    \begin{quote}
\begin{itemize}
\tightlist
\item
  Introduction to \textbf{COVID-19} 
\item
  A well defined (and explained, as well) problem, that the whole world
  in going through, currently 
\item
  Statistical models to understanding the unfolding of COVID-19, with
  days 
\item
  A step-wise \emph{data analysis} approach to attain the most
  feasible/optimal solution 
\item
  Accurate and easily understandable visualizations to understand the
  scenario, even better 
\item
  Various data-science \emph{tests} and \emph{algorithms} to bring
  sharpness and accuracy to the research 
\item
  Predictions for upcoming based on the studies and scientific analysis
  done 
\end{itemize}
\end{quote}

\begin{itemize}
\tightlist
\item
  \emph{This is a working project on the real time data} 
\end{itemize}

    \hypertarget{index}{%
\section{INDEX}\label{index}}

\begin{quote}
\mbox{}%
\hypertarget{introduction}{%
\paragraph{1. Introduction}\label{introduction}}

\mbox{}%
\hypertarget{business-understanding}{%
\paragraph{2. Business Understanding}\label{business-understanding}}

\mbox{}%
\hypertarget{data-understanding}{%
\paragraph{3. Data Understanding}\label{data-understanding}}

\mbox{}%
\hypertarget{data-preparation}{%
\paragraph{4. Data Preparation}\label{data-preparation}}

\mbox{}%
\hypertarget{modeling}{%
\paragraph{5. Modeling}\label{modeling}}

\mbox{}%
\hypertarget{evaluation}{%
\paragraph{6. Evaluation}\label{evaluation}}

\mbox{}%
\hypertarget{deployment}{%
\paragraph{7. Deployment}\label{deployment}}

\mbox{}%
\hypertarget{conclusion}{%
\paragraph{8. Conclusion}\label{conclusion}}

\mbox{}%
\hypertarget{bibliography}{%
\paragraph{9. Bibliography}\label{bibliography}}
\end{quote}

    

     A Predictive Data Analysis is a type of data-analysis where after the
complete statistical study of the data, the model predicts some estimate
when it receives a new datum. It can be for various types of predictions
categorization.

\begin{itemize}
\tightlist
\item
  Some other types of data-analysis can be Descriptive, Diagnostic or
  Prescriptive Analysis.
\end{itemize}

This Data Mining Project involves a sequence of (six) steps i.e.
\textgreater{} a) Business Understanding \textgreater{} b) Data
Understanding \textgreater{} c) Data Preparation \textgreater{} d)
Modeling \textgreater{} e) Evaluation \textgreater{} f) Deployment 

    

    \hypertarget{stepping-into-the-project}{%
\subsubsection{Stepping into the
project\ldots{}}\label{stepping-into-the-project}}

    

    Rate of growth of COVID-19 in China : within next one week

    

     \# Introduction

\begin{quote}
\begin{itemize}
\tightlist
\item
  History of Pandemics
\item
  novel Coronavirus Diseases: 2020
\item
  The Outbreak - COVID-19
\end{itemize}
\end{quote}

    \hypertarget{history-of-pandemics}{%
\subsubsection{History of Pandemics:}\label{history-of-pandemics}}

\begin{quote}
\begin{itemize}
\item
  Great Plague of Marseille: 1720

   As per the records Great Plague of Marseille started when a ship
  called Grand-Saint-Antoine docked in Marseille, France, carrying a
  cargo of goods from the eastern Mediterranean. It continued for the
  next three years, killing up to 30\% of the population of Marseille. 
\item
  First Cholera Pandemic: 1820

   In 1820 the First Cholera Pandemic occurred, in Asia, affecting
  countries, mainly Indonesia, Thailand and the Philippines. This
  pandemic has also killed about 100,000 as declared officially. It was
  a bacterial infection caused due to the contaminated water. 
\item
  Spanish Influenza/Flu: 1920

   Spanish Flu was the mose recent and the most unrelenting pandemics.
  It has infected about half a billion people and killed 100 million.
  The Spanish flu holds the official record for the deadliest pandemic
  officially recorded in history. 
\end{itemize}
\end{quote}

    \hypertarget{novel-coronavirus-disease-2020}{%
\subsubsection{novel Coronavirus Disease:
2020}\label{novel-coronavirus-disease-2020}}

 In the 21st century, novel Coronavirus Disease (COVID-19) has appeared
as the most severe pandemic, originated from Hubei province of China.
Caused by: \textbf{novel Coronavirus - 2} 

    \hypertarget{story-of-its-origin--}{%
\paragraph{Story of its origin -}\label{story-of-its-origin--}}

\begin{quote}
~\\
During November, 2019 - a severe viral infection was noticed in Wuhan, a
city in Hubei provinces of China. On November 17th 2019, the first case
this infection was reported. Doctor's initially took it lightly as if it
was a normal fever/cold. But, when a wide range of patients reported
similar symptoms, a doctor - Dr.~Li Wenliang of Chinese Academy of
Sciences (CAS) Lab, claimed that it was a type of severe acute
respiratory syndrome, spreading through a new coronavirus transmission
in the whole Hubei province, very rapidly. Reportedly, chainese
government warned him not to leak this anywhere. But anyhow, this news
got exposed during the late December, 2019. As per the sources, in 2003,
the same lab found first deadly SARS Coronavirus, led to 813 casualties,
all over the world, within two months! Initially, it was named as
``Wuhan Virus''. But, as it started spreading rapidly from Hubei to the
whole mainland of China, its name got replaced by term ``China Virus''.
\end{quote}

Finally, on Feb.~11th 2020, the World Health Organization (WHO) gave the
disease an official name: COVID-19. WHO has also declared the COVID-19
as a pandemic.

Since the outbreak of COVID-19, over 350000 people have been infected
throughout the world and over 15000 people have been killed.

\#\#\#\#

This map shows the daily spread of the 2019-vCoV

\hypertarget{covid-19-outbreak-in-world--}{%
\paragraph{COVID-19: Outbreak in world
-}\label{covid-19-outbreak-in-world--}}

\begin{quote}
~\\
A grand Cruise Ship called Diamond Princess was all set for it's two
weeks' journey from Yokohama (Japan) to China, Vietnam, Taiwan and back
to Japan. Guests boarded it on January 20th, but as the journey was
about to end, on February 1st tested positive for coronavirus, who
disembarked in Hong Kong on January 25th. The cruise was cancelled from
sailing as Japanese health instructors asked to check all the
passengers, along with the crew. And since then, the number of confirmed
cases for COVID-19 kept increasing. Currently, the ship was carrying
over 3500 people.
\end{quote}

     The COVID-19 is spread as rapidly as it has the Reproducibility Score
(R-naught) 2.9. Reproducibility Score: is meant for the number of
average persons, whom an infected person is further infecting. In more
generalized language, on an average, from every COVID-19 patient, virus
are getting transmitted to at least 2.9 fit persons. For Ebola, this
number is appx. 1.7 In order to have controle on any epidemic, the
reproducibility score has to be decreased as much as possible. That's
why, most of the highly countries are locked down. In many of them,
there are the shortage of hospitals/beds/doctors, too. Due to the
lockdown, the market is also going down.

As per the data available, following graphs show the 2019-nCoV cases
have increased since Jan.~22nd:

 * Confirmed Cases: * Death Cases: 

    \hypertarget{the-outbreak---covid-19}{%
\subsubsection{The Outbreak - COVID-19:}\label{the-outbreak---covid-19}}

\hypertarget{expended-form}{%
\subsubsection{Expended form:}\label{expended-form}}

 * `CO' : refers to corona * `VI' : refers to virus * `D' : refers to
disease * 19 : stands for the year (2019), when this virus appeared,
initially 

     \#\#\# Symptoms: The severe acute respiratory syndrome COVID-19
(SARS-CoV-19), which is often termed as 2019-nCoV, as well, is basically
a viral disease spread by the novel coronavirus in which the virus tend
to attack onto the respiratory system of the patient.

Though the studies are still going on, following are some most common
symptoms of COVID-19, known so far: \textgreater{} 1. Fever
\textgreater{} 2. Dry Cough \textgreater{} 3. Fatigue \textgreater{} 4.
Shortness of Breath \textgreater{} 5. Nasal Congestion etc..

These are the symptoms that are reported by most of the patients. Apart
from these, few patients also found to develop aches and pains and get
the sniffles, according to data from China. 

    \hypertarget{business-understanding}{%
\subsection{Business Understanding:}\label{business-understanding}}

     Now we all are well aware that this is a very severe pandemic i.e.~the
pandemic of 21st century. Not only this but another major problem is
that it has been around 5 months, since when the 2019-nCoV appeared,
first. Scientists are still trying to create the vaccine as soon as
possible, but for now, no final cure is up.

 

    \#\#

CONTRIBUTION OF THIS PROJECT

     Due to this pandemic:

\begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Almost every country in the world has atleast one confirm case of
  COVID-19
\item
  The diseases is spreading very rapidly
\item
  Economy of various countries is going down
\item
  Casualties are increasing even more fastly etc..
\end{enumerate}
\end{quote}

China, being the origin of the COVID-19, is the most affected country,
in the world.

    \hypertarget{this-becomes-more-clear-from-the-following-wordclouds}{%
\paragraph{* This becomes more clear from the following
wordclouds}\label{this-becomes-more-clear-from-the-following-wordclouds}}

(total confirmed cases \& deaths due to coronavirus till 21/03/2020) 

    * Here we find the China to be the most affected country!

     This projects to aims to find an estimate about the rate of
increase/decrease in appearance of new cases for next one week, in case
of China. 1. This estimate can help the country to know how much new
beds/hospitals are going to be required within next few days. 2. As the
economy is also going down, the outcome of this project can be far more
helpful for the country in terms of the financial planning. 3. It would
convey a more precise information for deciding that how the money has to
be divided for the constructions of new hospitals/isolation centers,
COVID-19 test kits, other medical equipments, caring and treatments,
etc.. This all would be helpful for other countries as well, in order to
bring the Reproducibility Score (R-naught) down to an acceptable limit.
(by applying useful strategies of China) 

    \begin{itemize}
\tightlist
\item
  We'll be preparing separate datasets for generating few of these
  visualization, while data-preparation phase.
\item
  For understanding how these visuals are developed from scratch, please
  refer to this link.
\end{itemize}

    

    \hypertarget{data-understanding}{%
\subsection{Data Understanding:}\label{data-understanding}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  DATA \& PROBLEM STATEMENT
\item
  BEGINNING WITH THE CODING SECTION
\item
  DATA COLLECTION
\end{itemize}
\end{quote}

    \hypertarget{data-problem-statement}{%
\subsubsection{* Data \& Problem
Statement}\label{data-problem-statement}}

    Our is aim to analyze that what would be the status of the epidemic will
change, within a week and hence, how log it might take to China to have
its control over this infection Further, we'd aim to generalize it for
any of the country, so that we could find the status of the same,
whenever required. Obviously, we'd have to change few parameters, tho'
we won't have to waste our time again and again in data preparation for
a particular country.

Hence we need the data about: \textgreater{} 1. Confirmed cases of
COVID-19, throughout the world \textgreater{} 2. Death cases due to
COVID-19, throughout the world \textgreater{} 3. Total Recovery from
COVID-19, throughout the world

We've collected this data from various sources including CSSE @Johns
Hopkins University, WHO \& MHRD - India. 

    \hypertarget{beginning-with-the-coding-section}{%
\paragraph{Beginning with the coding
section:}\label{beginning-with-the-coding-section}}

    \begin{quote}
 Let's start with setting-up our working directory and load all the
required packages, that we would be required:
\end{quote}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Setting the working directory}
\PY{n+nf}{options}\PY{p}{(}\PY{n}{warn}\PY{o}{=}\PY{l+m}{\PYZhy{}1}\PY{p}{)}
\PY{n+nf}{setwd}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZti{}/Documents/A\PYZhy{}tracking\PYZhy{}of\PYZhy{}2019\PYZhy{}nCoV/COVID\PYZhy{}19/\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}  Loading LIBRARIES  \PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{stringr}\PY{p}{)}

\PY{n+nf}{library}\PY{p}{(}\PY{n}{AUCRF}\PY{p}{)}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{randomForest}\PY{p}{)}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{RFmarkerDetector}\PY{p}{)}

\PY{n+nf}{library}\PY{p}{(}\PY{n}{caret}\PY{p}{)}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{mlbench}\PY{p}{)}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{kernlab}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Loading required package: randomForest

randomForest 4.6-14

Type rfNews() to see new features/changes/bug fixes.

AUCRF 1.1

Registered S3 methods overwritten by 'ggplot2':
  method         from
  [.quosures     rlang
  c.quosures     rlang
  print.quosures rlang


Attaching package: ‘RFmarkerDetector’


The following object is masked from ‘package:stats’:

    screeplot


Loading required package: lattice

Loading required package: ggplot2


Attaching package: ‘ggplot2’


The following object is masked from ‘package:randomForest’:

    margin



Attaching package: ‘kernlab’


The following object is masked from ‘package:ggplot2’:

    alpha


    \end{Verbatim}

    

    \hypertarget{data-collection}{%
\subsubsection{* Data Collection}\label{data-collection}}

    Basically, we have collected the raw data from websites and GitHub
repository.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} loading raw data}
\PY{n}{check.Confirmed} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/raw/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Confirmed.csv\PYZdq{}}\PY{p}{)}
\PY{n}{check.Deaths} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/raw/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Deaths.csv\PYZdq{}}\PY{p}{)}
\PY{n}{check.Recovered} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/raw/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Recovered.csv\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    The data, that we have collected is in the CSV (i.e. ``comma-separated
values'') format. A CSV file is used to store the structured data
row-wise, where the data elements in each rows are separated by a comma
(,).

It's pretty similar to the following:

\begin{verbatim}
Belinda Jameson,2017,Cushing House,148,3.52
Jeff Smith,2018,Prescott House,17-D,3.20
\end{verbatim}

 Let's view the head portion of our raw data:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} view sample}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	                  & Thailand         & 15.0000          &  101.0000        & 2                & 3                & 5                & 7                & 8                & 8                & ...              &  53              &  59              &  70              &  75              &  82              & 114              & 147              & 177              & 212              & 272             \\
	                  & Japan            & 36.0000          &  138.0000        & 2                & 1                & 2                & 2                & 4                & 4                & ...              & 581              & 639              & 639              & 701              & 773              & 839              & 825              & 878              & 889              & 924             \\
	                  & Singapore        &  1.2833          &  103.8333        & 0                & 1                & 3                & 3                & 4                & 5                & ...              & 160              & 178              & 178              & 200              & 212              & 226              & 243              & 266              & 313              & 345             \\
	                  & Nepal            & 28.1667          &   84.2500        & 0                & 0                & 0                & 1                & 1                & 1                & ...              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1             \\
	                  & Malaysia         &  2.5000          &  112.5000        & 0                & 0                & 0                & 3                & 4                & 4                & ...              & 129              & 149              & 149              & 197              & 238              & 428              & 566              & 673              & 790              & 900             \\
	 British Columbia & Canada           & 49.2827          & -123.1207        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  32              &  39              &  46              &  64              &  64              &  73              & 103              & 103              & 186              & 231             \\
\end{tabular}


    
    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	                  & Thailand         & 15.0000          &  101.0000        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  1               &  1               &  1               &  1               &  1               &  1               &  1               &  1               &  1               &  1              \\
	                  & Japan            & 36.0000          &  138.0000        & 0                & 0                & 0                & 0                & 0                & 0                & ...              & 10               & 15               & 16               & 19               & 22               & 22               & 27               & 29               & 29               & 29              \\
	                  & Singapore        &  1.2833          &  103.8333        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  0              \\
	                  & Nepal            & 28.1667          &   84.2500        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  0              \\
	                  & Malaysia         &  2.5000          &  112.5000        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  0               &  0               &  0               &  0               &  0               &  0               &  0               &  2               &  2               &  2              \\
	 British Columbia & Canada           & 49.2827          & -123.1207        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  1               &  1               &  1               &  1               &  1               &  1               &  4               &  4               &  7               &  7              \\
\end{tabular}


    
    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	                  & Thailand         & 15.0000          &  101.0000        & 0                & 0                & 0                & 0                & 2                & 2                & ...              &  33              &  34              &  34              &  35              &  35              &  35              &  35              &  41              &  42              &  42             \\
	                  & Japan            & 36.0000          &  138.0000        & 0                & 0                & 0                & 0                & 1                & 1                & ...              & 101              & 118              & 118              & 118              & 118              & 118              & 144              & 144              & 144              & 150             \\
	                  & Singapore        &  1.2833          &  103.8333        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  78              &  96              &  96              &  97              & 105              & 105              & 109              & 114              & 114              & 114             \\
	                  & Nepal            & 28.1667          &   84.2500        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1             \\
	                  & Malaysia         &  2.5000          &  112.5000        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  24              &  26              &  26              &  26              &  35              &  42              &  42              &  49              &  60              &  75             \\
	 British Columbia & Canada           & 49.2827          & -123.1207        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &   4              &   4              &   4              &   4              &   4              &   4              &   4              &   4              &   4              &   4             \\
\end{tabular}


    
    \hypertarget{we-can-see-that-type-of-collected-data-is-time-series}{%
\paragraph{We can see that type of collected data is:
time-series}\label{we-can-see-that-type-of-collected-data-is-time-series}}

\begin{quote}
A Time series data of a variable have a set of observations on values at
different points of time. They are usually collected at fixed intervals,
such as daily, weekly, monthly, annually, quarterly, etc.
\end{quote}

    We observe that all the three datasets have same columns as well as the
same type of data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} columns}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Number of columns in all 3 datasets:\PYZhy{}\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}

\PY{n+nf}{matrix}\PY{p}{(}
    \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Confirmed\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Deaths\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Recovered\PYZdq{}}\PY{p}{,} \PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{p}{,} \PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)}\PY{p}{,} \PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{n}{nrow} \PY{o}{=} \PY{l+m}{2}\PY{p}{,} \PY{n}{ncol} \PY{o}{=} \PY{l+m}{3}\PY{p}{,} \PY{n}{byrow} \PY{o}{=} \PY{n+nb+bp}{T}
\PY{p}{)}

\PY{c+c1}{\PYZsh{} Dimention}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Dimentions of datasets:\PYZhy{}\PYZbs{}n\PYZdq{}}\PY{p}{)}   \PY{c+c1}{\PYZsh{} same for all 3}
\PY{n+nf}{dim}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}


\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{c+c1}{\PYZsh{} columns\PYZsq{} name}
\PY{c+c1}{\PYZsh{}cat(\PYZdq{}Name of columns in all 3 datasets:\PYZhy{}\PYZbs{}n\PYZdq{})}

\PY{c+c1}{\PYZsh{}colnames(check.Confirmed)}
\PY{c+c1}{\PYZsh{}colnames(check.Deaths)}
\PY{c+c1}{\PYZsh{}colnames(check.Recovered)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of columns in all 3 datasets:-

    \end{Verbatim}

    \begin{tabular}{lll}
	 Confirmed & Deaths    & Recovered\\
	 62        & 62        & 62       \\
\end{tabular}


    
    \begin{Verbatim}[commandchars=\\\{\}]
Dimentions of datasets:-
    \end{Verbatim}

    \begin{enumerate*}
\item 468
\item 62
\end{enumerate*}


    
     Let's see the structure of these datasets:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{str}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}
\PY{c+c1}{\PYZsh{}str(check.Deaths)}
\PY{c+c1}{\PYZsh{}str(check.Recovered)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
'data.frame':   468 obs. of  62 variables:
 \$ Province.State: Factor w/ 321 levels "","Adams, IN",..: 1 1 1 1 1 25 196 298
237 1 {\ldots}
 \$ Country.Region: Factor w/ 155 levels "Afghanistan",..: 142 76 129 103 90 27 8
8 8 25 {\ldots}
 \$ Lat           : num  15 36 1.28 28.17 2.5 {\ldots}
 \$ Long          : num  101 138 103.8 84.2 112.5 {\ldots}
 \$ X1.22.20      : int  2 2 0 0 0 0 0 0 0 0 {\ldots}
 \$ X1.23.20      : int  3 1 1 0 0 0 0 0 0 0 {\ldots}
 \$ X1.24.20      : int  5 2 3 0 0 0 0 0 0 0 {\ldots}
 \$ X1.25.20      : int  7 2 3 1 3 0 0 0 0 0 {\ldots}
 \$ X1.26.20      : int  8 4 4 1 4 0 3 1 0 0 {\ldots}
 \$ X1.27.20      : int  8 4 5 1 4 0 4 1 0 1 {\ldots}
 \$ X1.28.20      : int  14 7 7 1 4 1 4 1 0 1 {\ldots}
 \$ X1.29.20      : int  14 7 7 1 7 1 4 1 1 1 {\ldots}
 \$ X1.30.20      : int  14 11 10 1 8 1 4 2 3 1 {\ldots}
 \$ X1.31.20      : int  19 15 13 1 8 1 4 3 2 1 {\ldots}
 \$ X2.1.20       : int  19 20 16 1 8 1 4 4 3 1 {\ldots}
 \$ X2.2.20       : int  19 20 18 1 8 1 4 4 2 1 {\ldots}
 \$ X2.3.20       : int  19 20 18 1 8 1 4 4 2 1 {\ldots}
 \$ X2.4.20       : int  25 22 24 1 10 1 4 4 3 1 {\ldots}
 \$ X2.5.20       : int  25 22 28 1 12 2 4 4 3 1 {\ldots}
 \$ X2.6.20       : int  25 45 28 1 12 2 4 4 4 1 {\ldots}
 \$ X2.7.20       : int  25 25 30 1 12 4 4 4 5 1 {\ldots}
 \$ X2.8.20       : int  32 25 33 1 16 4 4 4 5 1 {\ldots}
 \$ X2.9.20       : int  32 26 40 1 16 4 4 4 5 1 {\ldots}
 \$ X2.10.20      : int  32 26 45 1 18 4 4 4 5 1 {\ldots}
 \$ X2.11.20      : int  33 26 47 1 18 4 4 4 5 1 {\ldots}
 \$ X2.12.20      : int  33 28 50 1 18 4 4 4 5 1 {\ldots}
 \$ X2.13.20      : int  33 28 58 1 19 4 4 4 5 1 {\ldots}
 \$ X2.14.20      : int  33 29 67 1 19 4 4 4 5 1 {\ldots}
 \$ X2.15.20      : int  33 43 72 1 22 4 4 4 5 1 {\ldots}
 \$ X2.16.20      : int  34 59 75 1 22 4 4 4 5 1 {\ldots}
 \$ X2.17.20      : int  35 66 77 1 22 5 4 4 5 1 {\ldots}
 \$ X2.18.20      : int  35 74 81 1 22 5 4 4 5 1 {\ldots}
 \$ X2.19.20      : int  35 84 84 1 22 5 4 4 5 1 {\ldots}
 \$ X2.20.20      : int  35 94 84 1 22 5 4 4 5 1 {\ldots}
 \$ X2.21.20      : int  35 105 85 1 22 6 4 4 5 1 {\ldots}
 \$ X2.22.20      : int  35 122 85 1 22 6 4 4 5 1 {\ldots}
 \$ X2.23.20      : int  35 147 89 1 22 6 4 4 5 1 {\ldots}
 \$ X2.24.20      : int  35 159 89 1 22 6 4 4 5 1 {\ldots}
 \$ X2.25.20      : int  37 170 91 1 22 7 4 4 5 1 {\ldots}
 \$ X2.26.20      : int  40 189 93 1 22 7 4 4 5 1 {\ldots}
 \$ X2.27.20      : int  40 214 93 1 23 7 4 4 5 1 {\ldots}
 \$ X2.28.20      : int  41 228 93 1 23 7 4 4 5 1 {\ldots}
 \$ X2.29.20      : int  42 241 102 1 25 8 4 7 9 1 {\ldots}
 \$ X3.1.20       : int  42 256 106 1 29 8 6 7 9 1 {\ldots}
 \$ X3.2.20       : int  43 274 108 1 29 8 6 9 9 1 {\ldots}
 \$ X3.3.20       : int  43 293 110 1 36 9 13 9 11 1 {\ldots}
 \$ X3.4.20       : int  43 331 110 1 50 12 22 10 11 1 {\ldots}
 \$ X3.5.20       : int  47 360 117 1 50 13 22 10 13 1 {\ldots}
 \$ X3.6.20       : int  48 420 130 1 83 21 26 10 13 1 {\ldots}
 \$ X3.7.20       : int  50 461 138 1 93 21 28 11 13 1 {\ldots}
 \$ X3.8.20       : int  50 502 150 1 99 27 38 11 15 2 {\ldots}
 \$ X3.9.20       : int  50 511 150 1 117 32 48 15 15 2 {\ldots}
 \$ X3.10.20      : int  53 581 160 1 129 32 55 18 18 2 {\ldots}
 \$ X3.11.20      : int  59 639 178 1 149 39 65 21 20 3 {\ldots}
 \$ X3.12.20      : int  70 639 178 1 149 46 65 21 20 3 {\ldots}
 \$ X3.13.20      : int  75 701 200 1 197 64 92 36 35 5 {\ldots}
 \$ X3.14.20      : int  82 773 212 1 238 64 112 49 46 7 {\ldots}
 \$ X3.15.20      : int  114 839 226 1 428 73 134 57 61 7 {\ldots}
 \$ X3.16.20      : int  147 825 243 1 566 103 171 71 68 7 {\ldots}
 \$ X3.17.20      : int  177 878 266 1 673 103 210 94 78 33 {\ldots}
 \$ X3.18.20      : int  212 889 313 1 790 186 267 121 94 35 {\ldots}
 \$ X3.19.20      : int  272 924 345 1 900 231 307 121 144 37 {\ldots}
    \end{Verbatim}

    \hypertarget{explanation-of-each-columns-in-fetched-data-}{%
\subsubsection{Explanation of each columns in fetched
data:-}\label{explanation-of-each-columns-in-fetched-data-}}

\begin{itemize}
\tightlist
\item
  There are 3 dedicated databases for data about
  Confirmed/Death/Recovery cases, all around the world
\end{itemize}

\begin{quote}
\mbox{}%
\hypertarget{province.state}{%
\paragraph{Province.State:}\label{province.state}}

\begin{itemize}
\tightlist
\item
  Data-type: \textbf{factor} they can be specific, unique and valid
  names
\item
  Holds name of City/Province/State, where the data is coming from
\item
  Eg.: \emph{Hubei}
\end{itemize}

\mbox{}%
\hypertarget{country.region}{%
\paragraph{Country.Region:}\label{country.region}}

\begin{itemize}
\tightlist
\item
  Data-type: \textbf{factor} they can be specific, unique and valid
  names
\item
  Holds name of the country, in which the reported area comes
\item
  Eg.: \emph{China} (Hubei is a Province of China)
\end{itemize}

\mbox{}%
\hypertarget{lat}{%
\paragraph{Lat:}\label{lat}}

\begin{itemize}
\tightlist
\item
  Data-type: \textbf{numeric} (i.e.~can have values in decimals, too)
\item
  Holds the Latitude position of the given place(as in col1)
\item
  Eg.: \emph{Latitude} position of Hubei = 30.9756
\end{itemize}

\mbox{}%
\hypertarget{long}{%
\paragraph{Long:}\label{long}}

\begin{itemize}
\tightlist
\item
  Data-type: \textbf{numeric} (i.e.~can have values in decimals, too)
\item
  Holds the longitude position of the given place(as in col1)
\item
  Eg.: \emph{Longitude} position of Hubei = 112.2707
\end{itemize}

\mbox{}%
\hypertarget{col.-5-to-62}{%
\paragraph{Col. 5 to 62:}\label{col.-5-to-62}}

\begin{itemize}
\tightlist
\item
  Data-type: \textbf{integer} (i.e.~discrete) and remains \emph{always
  positive} as it determines the \emph{no, of individuals}
\item
  It's a time series data where the data is collected at various
  interval of time
\item
  Each datum value is represented, based on the different days in series
  (from 22/01/2020)
\item
  The constant entity is the location, whose data is represented in
  every row
\end{itemize}
\end{quote}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} showing data of Hubei}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nA sample data of a location from \PYZbs{}\PYZdq{}Confirmed Cases\PYZbs{}\PYZsq{}\PYZbs{}\PYZdq{} dataset:\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

A sample data of a location from "Confirmed Cases'" dataset:
    \end{Verbatim}

    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
  & Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	155 & Hubei    & China    & 30.9756  & 112.2707 & 444      & 444      & 549      & 761      & 1058     & 1423     & ...      & 67760    & 67773    & 67781    & 67786    & 67790    & 67794    & 67798    & 67799    & 67800    & 67800   \\
\end{tabular}


    
    

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} add required visualizations to understand why we are taking which specific step}
\end{Verbatim}
\end{tcolorbox}

    

    \hypertarget{data-preparation}{%
\subsection{Data Preparation:}\label{data-preparation}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  DATA CLEANING
\item
  DATA REDUCTION
\item
  Scaling
\item
  DATA TRANSFORMATION
\item
  Arranging data Country-Wise
\item
  Pooled Datasets
\end{itemize}
\end{quote}

    Now, as we have the raw data for our analysis, we can move forward for
our next phase i.e.~Data-Preparation. * The data-preparation is
considered to be the most time consuming phase of any datascience
project. * On an average, an idal data-science project's 90\% of time is
spent during Data-Collection and Data-Preparation.

    \hypertarget{data-cleaning}{%
\paragraph{* Data Cleaning}\label{data-cleaning}}

    Whenever we collect any kind of the raw-data from various sourcev, it
has a lot of the vulnerabilities. Most often, these are of following
types: 1. NAs and NaNs 2. Missing data values 3. Incorrect data values
Checking for these flaws in our data:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} sample NA values}
\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}

\PY{c+c1}{\PYZsh{} sample wrong data \PYZdq{}french guiana\PYZdq{} the data value can not decrease on next day}
\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{French Guiana\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}

\PY{c+c1}{\PYZsh{} sample blank data \PYZhy{}\PYZhy{}\PYZhy{}\PYZgt{} State (to be replaced by \PYZsq{}Others\PYZsq{})}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

        Error in eval(expr, envir, enclos): object 'check.Confirmed' not found
    Traceback:


    \end{Verbatim}

     So, there are also many issues (like blanks in the place of states'
name and data of a Cruise Ship among countries' data) with our available
datasets. To get rid of these issues, the data-cleaning is performed.

For data cleaning,we consider either of these two methods (or both,
too): 1. \textbf{Removal:} Here we usually remove or delete those
rows/columns, where we find the vulnerabilities. These rows/columns
might include NAs. 2. \textbf{Replacement/Filling:} Here we replace the
NAs or incorrect or blanks data values with some acceptable value.
Mostly, values are replaced by Mean or Mode values, so that the overall
statistical structure may remain the same. Sometimes, we also fill them
on the basis of some specific calculations.

    \hypertarget{what-will-we-do}{%
\subsubsection{What will we do?}\label{what-will-we-do}}

    Because we have the time-series dataset populated with discrete data
values, storing the total count of the total people (having COVID-19
confirmed, have died due to COVID-19 or have recovered from COVID-19),
the issues: \textgreater{} 1. can NOT be resolved by MEAN \textgreater{}
because in our case, either the Data value can remain CONSTANT or can
INCREASE, on every next day. \textgreater{} the MEAN need not to be
discrete \textgreater{} MEAN can also be less than the previous data,
for any particular day etc.. \textgreater{} 2. can NOT be resolved by
MODE \textgreater{} because it's a medical data and hence any most often
occurring number cannot be blindly replaced with a missing value etc..

Hence, we'll \textbf{NOT} be using any of the \textbf{replacement of
MEAN/MODE/MEDIAN}

    \hypertarget{well-replace-with-maximum-values}{%
\paragraph{We'll replace with maximum
values}\label{well-replace-with-maximum-values}}

We will be replacing the missing values or NAs with the maximum value up
to a day before the current day. It means that - the values are carried
constant for the next day whose data is missing.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} removing NAs, replacing incorrect values}

\PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
  \PY{n+nf}{for }\PY{p}{(}\PY{n}{j} \PY{n}{in} \PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
    \PY{n+nf}{if}\PY{p}{(}\PY{n}{j}\PY{o}{==}\PY{l+m}{5}\PY{p}{)} \PY{p}{\PYZob{}}
      \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n+nf}{ifelse}\PY{p}{(}\PY{n+nf}{is.na}\PY{p}{(}\PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{,} \PY{l+m}{0}\PY{p}{,} \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]}\PY{p}{)}
    \PY{p}{\PYZcb{}} \PY{n}{else} \PY{p}{\PYZob{}}
      \PY{n+nf}{if}\PY{p}{(}\PY{n+nf}{is.na}\PY{p}{(}\PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]}
      \PY{p}{\PYZcb{}} \PY{n}{else} \PY{n+nf}{if}\PY{p}{(}\PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]} \PY{o}{\PYZgt{}} \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]}
      \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
  \PY{p}{\PYZcb{}}
\PY{p}{\PYZcb{}}

\PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
  \PY{n+nf}{for }\PY{p}{(}\PY{n}{j} \PY{n}{in} \PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
    \PY{n+nf}{if}\PY{p}{(}\PY{n}{j}\PY{o}{==}\PY{l+m}{5}\PY{p}{)} \PY{p}{\PYZob{}}
      \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n+nf}{ifelse}\PY{p}{(}\PY{n+nf}{is.na}\PY{p}{(}\PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{,} \PY{l+m}{0}\PY{p}{,} \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]}\PY{p}{)}
    \PY{p}{\PYZcb{}} \PY{n}{else} \PY{p}{\PYZob{}}
      \PY{n+nf}{if}\PY{p}{(}\PY{n+nf}{is.na}\PY{p}{(}\PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]}
      \PY{p}{\PYZcb{}} \PY{n}{else} \PY{n+nf}{if}\PY{p}{(}\PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]} \PY{o}{\PYZgt{}} \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n}{check.Deaths}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]}
      \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
  \PY{p}{\PYZcb{}}
\PY{p}{\PYZcb{}}

\PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
  \PY{n+nf}{for }\PY{p}{(}\PY{n}{j} \PY{n}{in} \PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
    \PY{n+nf}{if}\PY{p}{(}\PY{n}{j}\PY{o}{==}\PY{l+m}{5}\PY{p}{)} \PY{p}{\PYZob{}}
      \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n+nf}{ifelse}\PY{p}{(}\PY{n+nf}{is.na}\PY{p}{(}\PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{,} \PY{l+m}{0}\PY{p}{,} \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]}\PY{p}{)}
    \PY{p}{\PYZcb{}} \PY{n}{else} \PY{p}{\PYZob{}}
      \PY{n+nf}{if}\PY{p}{(}\PY{n+nf}{is.na}\PY{p}{(}\PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]}
      \PY{p}{\PYZcb{}} \PY{n}{else} \PY{n+nf}{if}\PY{p}{(}\PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]} \PY{o}{\PYZgt{}} \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,} \PY{n}{j}\PY{n}{]}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{n}{check.Recovered}\PY{n}{[i}\PY{p}{,} \PY{p}{(}\PY{n}{j}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{n}{]}
      \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
  \PY{p}{\PYZcb{}}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} replace blanks and incorrect country/state names}

\PY{c+c1}{\PYZsh{} replacing in states}
\PY{n}{states} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{)}
\PY{n}{states.levels} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{n+nf}{levels}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{)}\PY{p}{)}

\PY{n}{states}\PY{n}{[states} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Others\PYZdq{}}
\PY{n}{states.levels}\PY{n}{[states.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Others\PYZdq{}}


\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{n}{states}\PY{n}{[states} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{From Diamond Princess\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Diamond Princess\PYZdq{}}
\PY{n}{states.levels} \PY{o}{=} \PY{n}{states.levels}\PY{n}{[}\PY{o}{!}\PY{n}{states.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{From Diamond Princess\PYZdq{}}\PY{n}{]}


\PY{c+c1}{\PYZsh{} replacing in countries}
\PY{n}{countries} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{)}
\PY{n}{countries.levels} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{n+nf}{levels}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{)}\PY{p}{)}

\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{US\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{United States\PYZdq{}}
\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{UK\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{United Kingdom\PYZdq{}}
\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Taiwan*\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Taiwan\PYZdq{}}
\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{The Bahamas\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Bahamas\PYZdq{}}
\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gambia, The\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gambia\PYZdq{}}
\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Korea, South\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{South Korea\PYZdq{}}
\PY{n}{countries}\PY{n}{[countries} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Congo (Brazzaville)\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Congo (Kinshasa)\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Republic of the Congo\PYZdq{}}\PY{p}{)}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Democratic Republic of the Congo\PYZdq{}}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}}
\PY{n}{countries.levels}\PY{n}{[countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{US\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{United States\PYZdq{}}
\PY{n}{countries.levels}\PY{n}{[countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{UK\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{United Kingdom\PYZdq{}}
\PY{n}{countries.levels}\PY{n}{[countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Taiwan*\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Taiwan\PYZdq{}}
\PY{n}{countries.levels}\PY{n}{[countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{The Bahamas\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Bahamas\PYZdq{}}
\PY{n}{countries.levels}\PY{n}{[countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gambia, The\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gambia\PYZdq{}}
\PY{n}{countries.levels}\PY{n}{[countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Korea, South\PYZdq{}}\PY{n}{]} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{South Korea\PYZdq{}}

\PY{n}{countries.levels} \PY{o}{=} \PY{n}{countries.levels}\PY{n}{[}\PY{o}{!}\PY{n}{countries.levels} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Congo (Brazzaville)\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Congo (Kinshasa)\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Republic of the Congo\PYZdq{}}\PY{p}{)}\PY{n}{]}
\PY{n}{countries.levels} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{countries.levels}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Democratic Republic of the Congo\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} rectified fectors}
\PY{n}{states.factor}  \PY{o}{=} \PY{n+nf}{factor}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{n}{states}\PY{p}{)}\PY{p}{,} \PY{n}{levels} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{states.levels}\PY{p}{)}\PY{p}{)}
\PY{n}{countries.factor}  \PY{o}{=} \PY{n+nf}{factor}\PY{p}{(}\PY{n}{countries}\PY{p}{,} \PY{n}{levels} \PY{o}{=} \PY{n}{countries.levels}\PY{p}{)}


\PY{c+c1}{\PYZsh{}\PYZsh{} CUZ\PYZsq{} INITIAL 4 COLUMNS ARE COMMON IN ALL 3 DATASETS \PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} editing factors in datasets}
\PY{n}{check.Confirmed} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}
                    \PY{n}{Province.State} \PY{o}{=} \PY{n}{states.factor}\PY{p}{,}
                    \PY{n}{Country.Region} \PY{o}{=} \PY{n}{countries.factor}\PY{p}{,}
                    \PY{n}{check.Confirmed}\PY{n}{[}\PY{p}{,}\PY{l+m}{3}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{]}
                  \PY{p}{)}

\PY{n}{check.Deaths} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}
                    \PY{n}{Province.State} \PY{o}{=} \PY{n}{states.factor}\PY{p}{,}
                    \PY{n}{Country.Region} \PY{o}{=} \PY{n}{countries.factor}\PY{p}{,}
                    \PY{n}{check.Deaths}\PY{n}{[}\PY{p}{,}\PY{l+m}{3}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)}\PY{n}{]}
                  \PY{p}{)}

\PY{n}{check.Recovered} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}
                    \PY{n}{Province.State} \PY{o}{=} \PY{n}{states.factor}\PY{p}{,}
                    \PY{n}{Country.Region} \PY{o}{=} \PY{n}{countries.factor}\PY{p}{,}
                    \PY{n}{check.Recovered}\PY{n}{[}\PY{p}{,}\PY{l+m}{3}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}\PY{n}{]}
                  \PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Now our data has been cleaned.} Viewing the cleaned data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} sample NA val}
\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}

\PY{c+c1}{\PYZsh{} sample wrong data \PYZdq{}french guiana\PYZdq{}}
\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{French Guiana\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}

\PY{c+c1}{\PYZsh{} sample blank data \PYZhy{}\PYZhy{}\PYZhy{}\PYZgt{} State (replaced by \PYZsq{}Other\PYZsq{})}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
  & Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	166 & Diamond Princess & Cruise Ship      & 35.4437          & 139.638          & 0                & 0                & 0                & 0                & 0                & 0                & ...              & 706              & 706              & 706              & 706              & 706              & 706              & 706              & 706              & 712              & 712             \\
\end{tabular}


    
    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
  & Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	431 & French Guiana & France        & 3.9339        & -53.1258      & 0             & 0             & 0             & 0             & 0             & 0             & ...           & 5             & 5             & 5             & 5             & 5             & 7             & 11            & 11            & 11            & 11           \\
\end{tabular}


    
    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	 Others           & Thailand         & 15.0000          &  101.0000        & 0                & 0                & 0                & 0                & 2                & 2                & ...              &  33              &  34              &  34              &  35              &  35              &  35              &  35              &  41              &  42              &  42             \\
	 Others           & Japan            & 36.0000          &  138.0000        & 0                & 0                & 0                & 0                & 1                & 1                & ...              & 101              & 118              & 118              & 118              & 118              & 118              & 144              & 144              & 144              & 150             \\
	 Others           & Singapore        &  1.2833          &  103.8333        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  78              &  96              &  96              &  97              & 105              & 105              & 109              & 114              & 114              & 114             \\
	 Others           & Nepal            & 28.1667          &   84.2500        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1              &   1             \\
	 Others           & Malaysia         &  2.5000          &  112.5000        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &  24              &  26              &  26              &  26              &  35              &  42              &  42              &  49              &  60              &  75             \\
	 British Columbia & Canada           & 49.2827          & -123.1207        & 0                & 0                & 0                & 0                & 0                & 0                & ...              &   4              &   4              &   4              &   4              &   4              &   4              &   4              &   4              &   4              &   4             \\
\end{tabular}


    
     \#\#\#\# * Data Reduction

    Though we have cleaned the dataset, yet we see that \textbf{`Diamond
Princess'} Cruise is still therein among the countries' data. Hence it's
an outlier, and hence has to be separated.

\textbf{So, now we'll start the process of data reduction}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} removing diamond princess}
\PY{n}{Diamond.Princess.Confirmed} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}
\PY{n}{check.Confirmed} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}

\PY{n}{Diamond.Princess.Deaths} \PY{o}{=} \PY{n}{check.Deaths}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Deaths}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}
\PY{n}{check.Deaths} \PY{o}{=} \PY{n}{check.Deaths}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Deaths}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}

\PY{n}{Diamond.Princess.Recovered} \PY{o}{=} \PY{n}{check.Recovered}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Recovered}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}
\PY{n}{check.Recovered} \PY{o}{=} \PY{n}{check.Recovered}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Recovered}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Cruise Ship\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}

\PY{c+c1}{\PYZsh{}\PYZsh{} Rectifying Row sequences}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Verifying if it is removed or not:}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s check whether Diamond Princess is still at row 166 or not}
\PY{n}{check.Confirmed}\PY{n}{[166}\PY{p}{,}\PY{n}{]}
\PY{c+c1}{\PYZsh{}check.Deaths[166,]}
\PY{c+c1}{\PYZsh{}check.Recovered[166,]}


\PY{c+c1}{\PYZsh{} also checking dimention}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nEarlier dimention: 468 X 62\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}    \PY{c+c1}{\PYZsh{} as we saw initially}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{New dimention: \PYZdq{}}\PY{p}{,} \PY{n+nf}{dim}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
  & Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	166 & Jiangsu & China   & 32.9711 & 119.455 & 1       & 5       & 9       & 18      & 33      & 47      & ...     & 631     & 631     & 631     & 631     & 631     & 631     & 631     & 631     & 631     & 631    \\
\end{tabular}


    
    \begin{Verbatim}[commandchars=\\\{\}]

Earlier dimention: 468 X 62

New dimention:  467 62
    \end{Verbatim}

    \emph{\textbf{OK! so it's gone!}} 

    \hypertarget{scaling}{%
\paragraph{Scaling}\label{scaling}}

    Now we have the dataset that hold the counts of the COVID-19 cases of
different geographical locations. Hence, we can now create a dataset to
generate the map for every unique day.(that we saw early in this
project)

\begin{itemize}
\item
  It means, we want to plot all the countries/regions that are affected
  on a particular day
\item
  It gives us an idea that - among all the given countries, either we
  are going to plot a selected country on world-map, or not, for a
  specific day
\item
  the \textbf{factor} on which basis we'll be deciding is - whether
  country has any confirmed case till that day or not
\item
  So, We'd also \textbf{need} the \emph{Latitude and Longitude} position
  for those country 
\end{itemize}

Finally, we can roughly estimate that we can have only 2 choices for any
region, say \textbf{0} \& \textbf{1}, such that: \textgreater{}
\textbf{0}: don't plot on map, if it has no confirm cases i.e.~val for
total confirm case on that day are 0 \textgreater{} \textbf{1}: plot on
map, if it has some confirm cases i.e.~there is at least 1 confirm case
on that day 

     Therefor, We're going to use \textbf{Unit Scaling} to set all the
values from 5th to last column 

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} in UNIT SCALING, all the data has either 0 or 1 value}

\PY{n}{ever.Affected} \PY{o}{=} \PY{n}{check.Confirmed}

\PY{c+c1}{\PYZsh{} Unit scaling}
\PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{n+nf}{row.names}\PY{p}{(}\PY{n}{ever.Affected}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
  \PY{n+nf}{for }\PY{p}{(}\PY{n}{j} \PY{n}{in} \PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{ever.Affected}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
    \PY{n+nf}{if}\PY{p}{(}\PY{n}{ever.Affected}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{!=} \PY{l+m}{0}\PY{p}{)}
      \PY{n}{ever.Affected}\PY{n}{[i}\PY{p}{,}\PY{n}{j}\PY{n}{]} \PY{o}{=} \PY{l+m}{1}
  \PY{p}{\PYZcb{}}
\PY{p}{\PYZcb{}}

\PY{n+nf}{head}\PY{p}{(}\PY{n}{ever.Affected}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	 Others           & Thailand         & 15.0000          &  101.0000        & 1                & 1                & 1                & 1                & 1                & 1                & ...              & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1               \\
	 Others           & Japan            & 36.0000          &  138.0000        & 1                & 1                & 1                & 1                & 1                & 1                & ...              & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1               \\
	 Others           & Singapore        &  1.2833          &  103.8333        & 0                & 1                & 1                & 1                & 1                & 1                & ...              & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1               \\
	 Others           & Nepal            & 28.1667          &   84.2500        & 0                & 0                & 0                & 1                & 1                & 1                & ...              & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1               \\
	 Others           & Malaysia         &  2.5000          &  112.5000        & 0                & 0                & 0                & 1                & 1                & 1                & ...              & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1               \\
	 British Columbia & Canada           & 49.2827          & -123.1207        & 0                & 0                & 0                & 0                & 0                & 0                & ...              & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1                & 1               \\
\end{tabular}


    
    \hypertarget{next-step-is-to-find-and-remove-the-outliers}{%
\paragraph{Next step is to find and remove the
outliers:}\label{next-step-is-to-find-and-remove-the-outliers}}

We'll use \textbf{scatter plots} \& \textbf{box plots} to
\emph{identify} and \textbf{compare the MEAN} of every day to
\emph{verify} these outliers, so that we can remove them, successfully.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{93}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s visualize our data to varify:}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{ggplot2}\PY{p}{)}

\PY{n+nf}{options}\PY{p}{(}\PY{n}{repr.plot.width}\PY{o}{=}\PY{l+m}{14}\PY{p}{,} \PY{n}{repr.plot.height}\PY{o}{=}\PY{l+m}{8}\PY{p}{)}
\PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{n+nf}{aes}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{X1.29.20}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{red\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{2}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme}\PY{p}{(}
          \PY{n}{text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gill Sans\PYZdq{}}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.subtitle} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{25}\PY{p}{,} \PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Courier\PYZdq{}}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{12}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text.x} \PY{o}{=} \PY{n+nf}{element\PYZus{}blank}\PY{p}{(}\PY{p}{)}
  \PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{}ggplot(check.Deaths) +}
\PY{c+c1}{\PYZsh{}  geom\PYZus{}point(aes(x=check.Deaths\PYZdl{}Province.State, y=check.Deaths\PYZdl{}X1.29.20), color=\PYZdq{}red\PYZdq{}, size=2)\PYZsh{}}

\PY{c+c1}{\PYZsh{}ggplot(check.Recovered) +}
\PY{c+c1}{\PYZsh{}  geom\PYZus{}point(aes(x=check.Recovered\PYZdl{}Province.State, y=check.Recovered\PYZdl{}X1.29.20), color=\PYZdq{}red\PYZdq{}, size=2)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]


    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_75_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s find the name of this outlier:\PYZhy{}}

\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{X1.29.20} \PY{o}{\PYZgt{}} \PY{l+m}{400}\PY{p}{)}\PY{p}{,} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Province.State\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Country.Region\PYZdq{}}\PY{p}{)}\PY{n}{]}
\PY{c+c1}{\PYZsh{}check.Deaths[which(check.Deaths\PYZdl{}X1.29.20 \PYZgt{} 15), c(\PYZdq{}Province.State\PYZdq{}, \PYZdq{}Country.Region\PYZdq{})]}
\PY{c+c1}{\PYZsh{}check.Recovered[which(check.Recovered\PYZdl{}X1.29.20 \PYZgt{} 20), c(\PYZdq{}Province.State\PYZdq{}, \PYZdq{}Country.Region\PYZdq{})]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|ll}
  & Province.State & Country.Region\\
\hline
	155 & Hubei & China\\
\end{tabular}


    
     So, it's \textbf{Hubei}. We'll verify it by comparison of mean value on
daily basis, including and excluding the Hubei province.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Here we are trying to compare the mean values of everyday, including and excluding Hubei province}
\PY{n}{With.Hubei} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n+nf}{apply}\PY{p}{(}\PY{n}{check.Confirmed}\PY{n}{[}\PY{p}{,}\PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{]}\PY{p}{,} \PY{l+m}{2}\PY{p}{,} \PY{n}{mean}\PY{p}{)}\PY{p}{)}

\PY{n}{exceptHubei} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}
\PY{n}{Without.Hubei} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n+nf}{apply}\PY{p}{(}\PY{n}{exceptHubei}\PY{n}{[}\PY{p}{,}\PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{exceptHubei}\PY{p}{)}\PY{n}{]}\PY{p}{,} \PY{l+m}{2}\PY{p}{,} \PY{n}{mean}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} creating a dataframe for comperision}
\PY{n}{Mean.Comparision.Table} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}
              \PY{l+s}{\PYZdq{}}\PY{l+s}{Date\PYZdq{}} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{n+nf}{colnames}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{[5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{]}\PY{p}{)}\PY{p}{,}
              \PY{l+s}{\PYZdq{}}\PY{l+s}{With Hubei\PYZdq{}} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{With.Hubei}\PY{p}{)}\PY{p}{,}
              \PY{l+s}{\PYZdq{}}\PY{l+s}{Without Hubei\PYZdq{}} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{Without.Hubei}\PY{p}{)}\PY{p}{)}

\PY{n+nf}{tail}\PY{p}{(}\PY{n}{Mean.Comparision.Table}\PY{p}{,} \PY{l+m}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
  & Date & With.Hubei & Without.Hubei\\
\hline
	49 & X3.10.20 & 253.5824 & 108.7189\\
	50 & X3.11.20 & 269.1563 & 124.2983\\
	51 & X3.12.20 & 274.4625 & 129.5987\\
	52 & X3.13.20 & 310.5567 & 165.7597\\
	53 & X3.14.20 & 333.8865 & 189.1309\\
	54 & X3.15.20 & 358.1949 & 213.4828\\
	55 & X3.16.20 & 388.4154 & 243.7597\\
	56 & X3.17.20 & 421.7794 & 277.1931\\
	57 & X3.18.20 & 459.9315 & 315.4249\\
	58 & X3.19.20 & 519.3191 & 374.9399\\
\end{tabular}


    
    So it's clear that the Hubei is the outlier..

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} let\PYZsq{}s remove Hubei from our dataset:}
\PY{n}{Hubei.Confirmed} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}
\PY{n}{check.Confirmed} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}

\PY{n}{Hubei.Deaths} \PY{o}{=} \PY{n}{check.Deaths}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Deaths}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}
\PY{n}{check.Deaths} \PY{o}{=} \PY{n}{check.Deaths}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Deaths}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}

\PY{n}{Hubei.Recovered} \PY{o}{=} \PY{n}{check.Recovered}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Recovered}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}
\PY{n}{check.Recovered} \PY{o}{=} \PY{n}{check.Recovered}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Recovered}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}


\PY{c+c1}{\PYZsh{}\PYZsh{} Rectifying Row sequences}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{check.Deaths}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{check.Recovered}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Hubei.Confirmed}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
  & Province.State & Country.Region & Lat & Long & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	155 & Hubei    & China    & 30.9756  & 112.2707 & 444      & 444      & 549      & 761      & 1058     & 1423     & ...      & 67760    & 67773    & 67781    & 67786    & 67790    & 67794    & 67798    & 67799    & 67800    & 67800   \\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s check the once dimention more}

\PY{c+c1}{\PYZsh{} also checking dimention}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nEarlier dimention: 467 X 62\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}    \PY{c+c1}{\PYZsh{} after removing Cruis Ship}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{New dimention: \PYZdq{}}\PY{p}{,} \PY{n+nf}{dim}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Earlier dimention: 467 X 62

New dimention:  466 62
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{75}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s visualize once more}
\PY{n+nf}{library}\PY{p}{(}\PY{n}{ggplot2}\PY{p}{)}

\PY{n+nf}{options}\PY{p}{(}\PY{n}{repr.plot.width}\PY{o}{=}\PY{l+m}{14}\PY{p}{,} \PY{n}{repr.plot.height}\PY{o}{=}\PY{l+m}{8}\PY{p}{)}
\PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{n+nf}{aes}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{X1.29.20}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{red\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{2}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme}\PY{p}{(}
          \PY{n}{text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gill Sans\PYZdq{}}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.subtitle} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{25}\PY{p}{,} \PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Courier\PYZdq{}}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{12}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text.x} \PY{o}{=} \PY{n+nf}{element\PYZus{}blank}\PY{p}{(}\PY{p}{)}
  \PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

        Error in ggplot(check.Confirmed): object 'check.Confirmed' not found
    Traceback:


        1. ggplot(check.Confirmed)

    \end{Verbatim}

     Although now it's comparatively better, still have some
outliers\ldots{}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s find them out, too:\PYZhy{}}
\PY{n}{check.Confirmed}\PY{n+nf}{[which}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{X1.29.20} \PY{o}{\PYZgt{}} \PY{l+m}{100}\PY{p}{)}\PY{p}{,} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Province.State\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Country.Region\PYZdq{}}\PY{p}{)}\PY{n}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|ll}
  & Province.State & Country.Region\\
\hline
	158 & Guangdong & China    \\
	159 & Henan     & China    \\
	160 & Zhejiang  & China    \\
	161 & Hunan     & China    \\
	162 & Anhui     & China    \\
	163 & Jiangxi   & China    \\
	164 & Shandong  & China    \\
	166 & Chongqing & China    \\
	167 & Sichuan   & China    \\
	170 & Beijing   & China    \\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Checking for mean comperision}
\PY{n}{With.China} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n+nf}{apply}\PY{p}{(}\PY{n}{check.Confirmed}\PY{n}{[}\PY{p}{,}\PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{]}\PY{p}{,} \PY{l+m}{2}\PY{p}{,} \PY{n}{mean}\PY{p}{)}\PY{p}{)}

\PY{n}{exceptChina} \PY{o}{=} \PY{n}{check.Confirmed}\PY{n}{[} \PY{n+nf}{which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{check.Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}}\PY{p}{,} \PY{n}{negate} \PY{o}{=} \PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{]}
\PY{n}{Without.China} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n+nf}{apply}\PY{p}{(}\PY{n}{exceptChina}\PY{n}{[}\PY{p}{,}\PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{exceptChina}\PY{p}{)}\PY{n}{]}\PY{p}{,} \PY{l+m}{2}\PY{p}{,} \PY{n}{mean}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} comperision}
\PY{n}{Mean.Comparision.Table} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}
              \PY{l+s}{\PYZdq{}}\PY{l+s}{Date\PYZdq{}} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{n+nf}{colnames}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{[5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{check.Confirmed}\PY{p}{)}\PY{n}{]}\PY{p}{)}\PY{p}{,}
              \PY{l+s}{\PYZdq{}}\PY{l+s}{With China\PYZdq{}} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{With.China}\PY{p}{)}\PY{p}{,}
              \PY{l+s}{\PYZdq{}}\PY{l+s}{Without China\PYZdq{}} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{Without.China}\PY{p}{)}\PY{p}{)}

\PY{n+nf}{head}\PY{p}{(}\PY{n}{Mean.Comparision.Table}\PY{p}{,} \PY{l+m}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
 Date & With.China & Without.China\\
\hline
	 X1.22.20   & 0.2381974  & 0.01612903\\
	 X1.23.20   & 0.4506438  & 0.02534562\\
	 X1.24.20   & 0.8412017  & 0.04838710\\
	 X1.25.20   & 1.4442060  & 0.06451613\\
	 X1.26.20   & 2.2746781  & 0.09907834\\
	 X1.27.20   & 3.2274678  & 0.11520737\\
	 X1.28.20   & 4.3433476  & 0.15898618\\
	 X1.29.20   & 5.6051502  & 0.18202765\\
	 X1.30.20   & 7.1480687  & 0.21428571\\
	 X1.31.20   & 8.8454936  & 0.29032258\\
\end{tabular}


    
    \begin{verbatim}
So, while talking about the whole world, the complete mainland of China seems to be the outlier.
Although, we'll have to verify it first.
\end{verbatim}

 But because, it's not a single row, we will perform this action later
i.e.~during data-transformation.

    

    \hypertarget{data-transformation}{%
\paragraph{* Data transformation}\label{data-transformation}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We\PYZsq{}ve already saved the cleaned version of the all the files}
\PY{c+c1}{\PYZsh{} Loading the files in order to transform the dataset(s)}

\PY{c+c1}{\PYZsh{} loading raw data \PYZhy{} from source}
\PY{n}{Confirmed} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Confirmed.csv\PYZdq{}}\PY{p}{)}
\PY{n}{Deaths} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Deaths.csv\PYZdq{}}\PY{p}{)}
\PY{n}{Recovered} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Recovered.csv\PYZdq{}}\PY{p}{)}

\PY{n}{Hubei.Confirmed} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/Hubei/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Confirmed.csv\PYZdq{}}\PY{p}{)}
\PY{n}{Hubei.Deaths} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/Hubei/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Deaths.csv\PYZdq{}}\PY{p}{)}
\PY{n}{Hubei.Recovered} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/Hubei/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Recovered.csv\PYZdq{}}\PY{p}{)}

\PY{n}{Diamond.Princess.Confirmed} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/Diamond\PYZhy{}Princess/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Confirmed.csv\PYZdq{}}\PY{p}{)}
\PY{n}{Diamond.Princess.Deaths} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/Diamond\PYZhy{}Princess/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Deaths.csv\PYZdq{}}\PY{p}{)}
\PY{n}{Diamond.Princess.Recovered} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Notebooks/syllabus/static/cleaned/Diamond\PYZhy{}Princess/time\PYZus{}series\PYZus{}19\PYZhy{}covid\PYZhy{}Recovered.csv\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} as known, all of these files have same set of columns,}
\PY{c+c1}{\PYZsh{} the only things that differ are data values in dates\PYZsq{} columns}

\PY{c+c1}{\PYZsh{} Let\PYZsq{}s see any one dataset\PYZsq{}s structure (as all are similer)}
\PY{n+nf}{str}\PY{p}{(}\PY{n}{Hubei.Recovered}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
'data.frame':   1 obs. of  62 variables:
 \$ State         : Factor w/ 1 level "Hubei": 1
 \$ Country.Region: Factor w/ 1 level "China": 1
 \$ Lat           : num 31
 \$ Long          : num 112
 \$ X1.22.20      : int 28
 \$ X1.23.20      : int 28
 \$ X1.24.20      : int 31
 \$ X1.25.20      : int 32
 \$ X1.26.20      : int 42
 \$ X1.27.20      : int 45
 \$ X1.28.20      : int 80
 \$ X1.29.20      : int 88
 \$ X1.30.20      : int 90
 \$ X1.31.20      : int 141
 \$ X2.1.20       : int 168
 \$ X2.2.20       : int 295
 \$ X2.3.20       : int 386
 \$ X2.4.20       : int 522
 \$ X2.5.20       : int 633
 \$ X2.6.20       : int 817
 \$ X2.7.20       : int 1115
 \$ X2.8.20       : int 1439
 \$ X2.9.20       : int 1795
 \$ X2.10.20      : int 2222
 \$ X2.11.20      : int 2639
 \$ X2.12.20      : int 2686
 \$ X2.13.20      : int 3459
 \$ X2.14.20      : int 4774
 \$ X2.15.20      : int 5623
 \$ X2.16.20      : int 6639
 \$ X2.17.20      : int 7862
 \$ X2.18.20      : int 9128
 \$ X2.19.20      : int 10337
 \$ X2.20.20      : int 11788
 \$ X2.21.20      : int 11881
 \$ X2.22.20      : int 15299
 \$ X2.23.20      : int 15343
 \$ X2.24.20      : int 16748
 \$ X2.25.20      : int 18971
 \$ X2.26.20      : int 20969
 \$ X2.27.20      : int 23383
 \$ X2.28.20      : int 26403
 \$ X2.29.20      : int 28993
 \$ X3.1.20       : int 31536
 \$ X3.2.20       : int 33934
 \$ X3.3.20       : int 36208
 \$ X3.4.20       : int 38557
 \$ X3.5.20       : int 40592
 \$ X3.6.20       : int 42033
 \$ X3.7.20       : int 43500
 \$ X3.8.20       : int 45235
 \$ X3.9.20       : int 46488
 \$ X3.10.20      : int 47743
 \$ X3.11.20      : int 49134
 \$ X3.12.20      : int 50318
 \$ X3.13.20      : int 51553
 \$ X3.14.20      : int 52960
 \$ X3.15.20      : int 54288
 \$ X3.16.20      : int 55142
 \$ X3.17.20      : int 56003
 \$ X3.18.20      : int 56927
 \$ X3.19.20      : int 57682
    \end{Verbatim}

     * Now, recalling the Problem Statement, we aim to find out the status
of COVID-19 in China, within next 7 days * In order to do so, we need to
analyze the status of COVID-19 on all the previous days

\hypertarget{what-would-it-tell-us}{%
\subsubsection{What would it tell us?}\label{what-would-it-tell-us}}

By this, we'd be capable enough to make an estimate by what RATE the
Coronavirus is spreading since late January. Hence, we need to transform
the data in order: \textgreater{} 1. such that rows hold every data
Country wise, instead of State wise \textgreater{} 2. to include a new
column ``Date'' to store aggregate data (of 3 datasets) in a single
place \textgreater{} 3. remove unnecessary columns i.e. \emph{States,
Latitude \& Longitude}

    \hypertarget{arranging-data-country-wise}{%
\paragraph{Arranging data
Country-Wise}\label{arranging-data-country-wise}}

 \textbf{Steps:}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{74}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} We need Countries\PYZsq{} data:}

\PY{c+c1}{\PYZsh{} It\PYZsq{}s because: many states have very few cases}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{Confirmed}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Most of the states\PYZsq{} name is not identified}
\PY{n}{unknown} \PY{o}{=} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{Recovered}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{Recovered}\PY{o}{\PYZdl{}}\PY{n}{Province.State}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Others\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}\PY{p}{)}
\PY{n+nf}{cat}\PY{p}{(}\PY{n}{unknown}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{/\PYZdq{}}\PY{p}{,} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{Recovered}\PY{p}{)}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{ States are NOT identified\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Ultimatly, any precaution/cure or action is more likely be taken onto the country level, rather than the individual state, as it\PYZsq{}s the case of a severe Epidemic}
\PY{c+c1}{\PYZsh{} Only then it would be much easier for us to make any possible estimate for the world as well, due to not having really a huge data about each and every single state of the countries.}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

        Error in tail(Confirmed): object 'Confirmed' not found
    Traceback:


        1. tail(Confirmed)

    \end{Verbatim}

     As we know that Country column is a \emph{Factor}, we can easily list
those countries', who have reported Confirmed cases (on the daily
basis):

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{Countries} \PY{o}{=} \PY{n+nf}{levels}\PY{p}{(}\PY{n}{Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTotal number of affected countries: \PYZdq{}}\PY{p}{,} \PY{n+nf}{nlevels}\PY{p}{(}\PY{n}{Confirmed}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{)}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZbs{}nCountries:\PYZdq{}}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{Countries}\PY{p}{)}\PY{p}{,} \PY{l+m}{5}\PY{p}{)} \PY{c+c1}{\PYZsh{} top 5 countries (in sorted list\PYZhy{}namewise)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Total number of affected countries:  153


Countries:
    \end{Verbatim}

    \begin{tabular}{l}
	 Afghanistan        \\
	 Albania            \\
	 Algeria            \\
	 Andorra            \\
	 Antigua and Barbuda\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{} Functions for extracting required data}


\PY{c+c1}{\PYZsh{} finds the total cases reported in given country }
    \PY{c+c1}{\PYZsh{} (by Adding all the data of different states in it)}
\PY{n}{country.aggregate.daily}  \PY{o}{\PYZlt{}\PYZhy{}}  \PY{n+nf}{function}\PY{p}{(}\PY{n}{dfName}\PY{p}{,} \PY{n}{country}\PY{p}{)} \PY{p}{\PYZob{}}
  
  \PY{n}{df} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{get}\PY{p}{(}\PY{n}{dfName}\PY{p}{)}
  \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{Country.Region}\PY{p}{,} \PY{n}{country}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}
  \PY{n}{df} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}\PY{n}{States} \PY{o}{=} \PY{n}{df}\PY{n}{[}\PY{p}{,}\PY{l+m}{1}\PY{n}{]}\PY{p}{,} \PY{n}{Country} \PY{o}{=} \PY{n}{df}\PY{n}{[}\PY{p}{,}\PY{l+m}{2}\PY{n}{]}\PY{p}{,} \PY{n}{df}\PY{n}{[}\PY{p}{,}\PY{l+m}{5}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{n}{]}\PY{p}{)}     \PY{c+c1}{\PYZsh{} ELEMINATING LATITUDE/LONGITUDE Col.}
  
  \PY{n+nf}{row.names}\PY{p}{(}\PY{n}{df}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}    
    
  \PY{n}{temp} \PY{o}{=} \PY{n}{df}                                             \PY{c+c1}{\PYZsh{} all states\PYZsq{} data of a country}
  \PY{n}{df} \PY{o}{=} \PY{n}{temp}\PY{n}{[1}\PY{p}{,}\PY{n}{]} 
  
  \PY{n}{df}\PY{n}{[3}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{temp}\PY{p}{)}\PY{n}{]} \PY{o}{=} \PY{n+nf}{apply}\PY{p}{(}   \PY{n}{temp}\PY{n}{[}\PY{p}{,}\PY{l+m}{3}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{temp}\PY{p}{)}\PY{n}{]}\PY{p}{,}
                            \PY{l+m}{2}\PY{p}{,}
                            \PY{n}{sum}
                        \PY{p}{)}                               \PY{c+c1}{\PYZsh{} applying sum of all the states\PYZsq{} values}
  \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{n}{[2}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{n}{]}                                   \PY{c+c1}{\PYZsh{} removing column \PYZsq{}States\PYZsq{}  }
  \PY{n+nf}{row.names}\PY{p}{(}\PY{n}{df}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}  
  \PY{n+nf}{return}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\PY{p}{\PYZcb{}}



\PY{c+c1}{\PYZsh{} generated a dataframe having required data arranged Country\PYZhy{}Wise }
    \PY{c+c1}{\PYZsh{} (by appending every single country\PYZsq{}s data)}
\PY{n}{countries.daily} \PY{o}{\PYZlt{}\PYZhy{}}  \PY{n+nf}{function}\PY{p}{(}\PY{n}{dfName}\PY{p}{,} \PY{n}{cList}\PY{p}{)} \PY{p}{\PYZob{}}
  
  \PY{n}{n} \PY{o}{=} \PY{n+nf}{length}\PY{p}{(}\PY{n}{cList}\PY{p}{)}       \PY{c+c1}{\PYZsh{} number of countries}
  
  \PY{n}{flag} \PY{o}{=} \PY{l+m}{0}
  
  \PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{n}{cList}\PY{p}{)} \PY{p}{\PYZob{}}
    
    \PY{n+nf}{if}\PY{p}{(}\PY{n}{flag} \PY{o}{==} \PY{l+m}{0}\PY{p}{)} \PY{p}{\PYZob{}}
      \PY{n}{df} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{n}{dfName}\PY{p}{,} \PY{n}{i}\PY{p}{)}
      \PY{n}{flag} \PY{o}{=} \PY{l+m}{1}
    \PY{p}{\PYZcb{}} \PY{n}{else} \PY{p}{\PYZob{}}
      \PY{n}{temp} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{n}{dfName}\PY{p}{,} \PY{n}{i}\PY{p}{)}
      \PY{n}{df} \PY{o}{=} \PY{n+nf}{rbind}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{n}{temp}\PY{p}{)}
    \PY{p}{\PYZcb{}}    
  \PY{p}{\PYZcb{}}
  
  \PY{n+nf}{row.names}\PY{p}{(}\PY{n}{df}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}  
  \PY{n+nf}{return}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{51}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{China.Confirmed} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Confirmed\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}}\PY{p}{)}
\PY{n}{World.Confirmed} \PY{o}{=} \PY{n+nf}{countries.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Confirmed\PYZdq{}}\PY{p}{,} \PY{n}{Countries}\PY{p}{)}

\PY{n}{China.Confirmed}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{World.Confirmed}\PY{p}{)}

\PY{n}{China.Deaths} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Deaths\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}}\PY{p}{)}
\PY{n}{World.Deaths} \PY{o}{=} \PY{n+nf}{countries.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Deaths\PYZdq{}}\PY{p}{,} \PY{n}{Countries}\PY{p}{)}
\PY{n}{China.Recovered} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Recovered\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}}\PY{p}{)}
\PY{n}{World.Recovered} \PY{o}{=} \PY{n+nf}{countries.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Recovered\PYZdq{}}\PY{p}{,} \PY{n}{Countries}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Country & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & X1.28.20 & X1.29.20 & X1.30.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	 China & 104   & 199   & 371   & 645   & 1017  & 1454  & 1955  & 2533  & 3238  & ...   & 13127 & 13148 & 13151 & 13159 & 13187 & 13209 & 13235 & 13259 & 13303 & 13357\\
\end{tabular}


    
    \begin{Verbatim}[commandchars=\\\{\}]


    \end{Verbatim}

    \begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}
 Country & X1.22.20 & X1.23.20 & X1.24.20 & X1.25.20 & X1.26.20 & X1.27.20 & X1.28.20 & X1.29.20 & X1.30.20 & ... & X3.10.20 & X3.11.20 & X3.12.20 & X3.13.20 & X3.14.20 & X3.15.20 & X3.16.20 & X3.17.20 & X3.18.20 & X3.19.20\\
\hline
	 Afghanistan         & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & ...                 &  5                  &  7                  &  7                  &  7                  & 11                  & 16                  & 21                  & 22                  & 22                  & 22                 \\
	 Albania             & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & ...                 & 10                  & 12                  & 23                  & 33                  & 38                  & 42                  & 51                  & 55                  & 59                  & 64                 \\
	 Algeria             & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & ...                 & 20                  & 20                  & 24                  & 26                  & 37                  & 48                  & 54                  & 60                  & 74                  & 87                 \\
	 Andorra             & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & ...                 &  1                  &  1                  &  1                  &  1                  &  1                  &  1                  &  2                  & 39                  & 39                  & 53                 \\
	 Antigua and Barbuda & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & ...                 &  0                  &  0                  &  0                  &  1                  &  1                  &  1                  &  1                  &  1                  &  1                  &  1                 \\
	 Argentina           & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & 0                   & ...                 & 17                  & 19                  & 19                  & 31                  & 34                  & 45                  & 56                  & 68                  & 79                  & 97                 \\
\end{tabular}


    
     \#\#\# Moving to next step

    \hypertarget{we-need-datewise-data}{%
\paragraph{We need datewise data:}\label{we-need-datewise-data}}

\begin{itemize}
\item
  It's so because, we aim to analyze data on the daily basis
  \textgreater{} Hence we'd have to add another column ``Date'' or
  simply ``Day'' (to hold day-\textgreater{} 1, 2\ldots{})
\item
  in order to do so, we'd have to transform our data into
  Cross-sectional (China, Hubei \& Diamond Princess) or Pooled data
  (Countries of world other than China)
\end{itemize}

 \#\#\#\# Let's understand what a Cross-sectional \& a Pooled data is:-
\textgreater{} * \textbf{Cross-sectional data:} Data of one or more
variables, collected at the same point in time. \textgreater{} *
\textbf{Pooled data:} A combination of time series data and
cross-sectional data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{53}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{} Functions}

\PY{n}{countries.daily.bulk.summary} \PY{o}{=} \PY{n+nf}{function}\PY{p}{(}\PY{n}{cList}\PY{p}{)} \PY{p}{\PYZob{}} \PY{c+c1}{\PYZsh{} date wise country data}
  
  \PY{c+c1}{\PYZsh{} structure of resulting dataset (initially blank)}
  \PY{n}{df} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
    \PY{n}{Country} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
    \PY{n}{Day} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}           \PY{c+c1}{\PYZsh{} day no.}
    \PY{n}{Date} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
    \PY{n}{Confirmed} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
    \PY{n}{Deaths} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
    \PY{n}{Recovered} \PY{o}{=} \PY{k+kc}{NULL}
  \PY{p}{)}
  
  \PY{c+c1}{\PYZsh{} calculating all countries\PYZsq{} data (date wise) through iteration}
  \PY{n+nf}{for}\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{n}{cList}\PY{p}{)} \PY{p}{\PYZob{}}
    \PY{n}{this.one.confirmed} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Confirmed\PYZdq{}}\PY{p}{,} \PY{n}{i}\PY{p}{)}
    \PY{n}{this.one.deaths} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Deaths\PYZdq{}}\PY{p}{,} \PY{n}{i}\PY{p}{)}
    \PY{n}{this.one.recovered} \PY{o}{=} \PY{n+nf}{country.aggregate.daily}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Recovered\PYZdq{}}\PY{p}{,} \PY{n}{i}\PY{p}{)}
    
    \PY{n}{times} \PY{o}{=} \PY{n+nf}{ncol}\PY{p}{(}\PY{n}{this.one.confirmed}\PY{p}{)}\PY{l+m}{\PYZhy{}1}      \PY{c+c1}{\PYZsh{} no. of days}
    \PY{n}{day} \PY{o}{=} \PY{l+m}{1}\PY{o}{:}\PY{n}{times}
    \PY{n}{d} \PY{o}{=} \PY{n+nf}{as.Date}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{21\PYZhy{}01\PYZhy{}2020\PYZdq{}}\PY{p}{,} \PY{n+nf}{format}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZpc{}d\PYZhy{}\PYZpc{}m\PYZhy{}\PYZpc{}Y\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
    
    \PY{n}{date} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{p}{(}\PY{n}{day} \PY{o}{+} \PY{n}{d}\PY{p}{)}\PY{p}{,} \PY{n+nf}{format}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZpc{}d\PYZhy{}\PYZpc{}m\PYZhy{}\PYZpc{}Y\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}      \PY{c+c1}{\PYZsh{} its lenngth is equal to \PYZhy{}\PYZhy{}\PYZgt{} no. of days}
    \PY{n}{date} \PY{o}{=} \PY{n+nf}{factor}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{n}{date}\PY{p}{)}\PY{p}{,} \PY{n}{levels} \PY{o}{=} \PY{n}{date}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{}max(Deaths.temp[1,5:ncol(Deaths.temp)])}
    \PY{n}{confirmed} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n}{this.one.confirmed}\PY{n}{[1}\PY{p}{,}\PY{l+m}{2}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{this.one.confirmed}\PY{p}{)}\PY{n}{]}\PY{p}{)}
    
    \PY{n}{deaths} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n}{this.one.deaths}\PY{n}{[1}\PY{p}{,}\PY{l+m}{2}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{this.one.deaths}\PY{p}{)}\PY{n}{]}\PY{p}{)}
    
    \PY{n}{recovered} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n}{this.one.recovered}\PY{n}{[1}\PY{p}{,}\PY{l+m}{2}\PY{o}{:}\PY{n+nf}{ncol}\PY{p}{(}\PY{n}{this.one.recovered}\PY{p}{)}\PY{n}{]}\PY{p}{)}
    
    \PY{n}{dataset} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
      \PY{n}{Country} \PY{o}{=} \PY{n+nf}{rep}\PY{p}{(}\PY{n}{i}\PY{p}{,} \PY{n}{times}\PY{p}{)}\PY{p}{,}
      \PY{n}{Day} \PY{o}{=} \PY{n+nf}{factor}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{l+m}{1}\PY{o}{:}\PY{n+nf}{length}\PY{p}{(}\PY{n}{date}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{levels} \PY{o}{=} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{length}\PY{p}{(}\PY{n}{date}\PY{p}{)}\PY{p}{)}\PY{p}{,}
      \PY{n}{Date} \PY{o}{=} \PY{n}{date}\PY{p}{,}
      \PY{n}{Confirmed} \PY{o}{=} \PY{n}{confirmed}\PY{p}{,}
      \PY{n}{Deaths} \PY{o}{=} \PY{n}{deaths}\PY{p}{,}
      \PY{n}{Recovered} \PY{o}{=} \PY{n}{recovered}
    \PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} joining this country}
    \PY{n}{df} \PY{o}{=} \PY{n+nf}{rbind}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{n}{dataset}\PY{p}{)}
  \PY{p}{\PYZcb{}}
    
  \PY{n+nf}{return}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{bulk} \PY{o}{=} \PY{n+nf}{countries.daily.bulk.summary}\PY{p}{(}\PY{n}{Countries}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{bulk}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllll}
 Country & Day & Date & Confirmed & Deaths & Recovered\\
\hline
	 Afghanistan & 1           & 22-01-2020  & 0           & 0           & 0          \\
	 Afghanistan & 2           & 23-01-2020  & 0           & 0           & 0          \\
	 Afghanistan & 3           & 24-01-2020  & 0           & 0           & 0          \\
	 Afghanistan & 4           & 25-01-2020  & 0           & 0           & 0          \\
	 Afghanistan & 5           & 26-01-2020  & 0           & 0           & 0          \\
	 Afghanistan & 6           & 27-01-2020  & 0           & 0           & 0          \\
\end{tabular}


    
     For better analysis, let's add 2 more columns: \textgreater{}
\textbf{1. Closed.Cases} = consists all cases, that are Expired or
Recovered \textgreater{} \textbf{2. Active.Cases} = cases that are
neither Expired nor Recovered

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{57}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Active.Cases} \PY{o}{=} \PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Confirmed} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Deaths} \PY{o}{+} \PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Recovered}\PY{p}{)}
\PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Closed.Cases} \PY{o}{=} \PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Deaths} \PY{o}{+} \PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Recovered}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{bulk}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
  & Country & Day & Date & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases\\
\hline
	8869 & Zambia     & 53         & 14-03-2020 & 0          & 0          & 0          & 0          & 0         \\
	8870 & Zambia     & 54         & 15-03-2020 & 0          & 0          & 0          & 0          & 0         \\
	8871 & Zambia     & 55         & 16-03-2020 & 0          & 0          & 0          & 0          & 0         \\
	8872 & Zambia     & 56         & 17-03-2020 & 0          & 0          & 0          & 0          & 0         \\
	8873 & Zambia     & 57         & 18-03-2020 & 2          & 0          & 0          & 2          & 0         \\
	8874 & Zambia     & 58         & 19-03-2020 & 2          & 0          & 0          & 2          & 0         \\
\end{tabular}


    
     So, our Pooled dataset ready. Let's understand this dataset:- 

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{58}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Analysing the Pooled data}
\PY{n+nf}{str}\PY{p}{(}\PY{n}{bulk}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
'data.frame':   8874 obs. of  8 variables:
 \$ Country     : Factor w/ 153 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 {\ldots}
 \$ Day         : Factor w/ 58 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10
{\ldots}
 \$ Date        : Factor w/ 58 levels "22-01-2020","23-01-2020",..: 1 2 3 4 5 6 7
8 9 10 {\ldots}
 \$ Confirmed   : num  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Deaths      : num  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Recovered   : num  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Active.Cases: num  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Closed.Cases: num  0 0 0 0 0 0 0 0 0 0 {\ldots}
    \end{Verbatim}

    \hypertarget{explanation-of-pooled-datasets-bulk-four}{%
\subsection{Explanation of Pooled Datasets (bulk \&
four)}\label{explanation-of-pooled-datasets-bulk-four}}

 * Pooled data is a combination of time series data and cross-sectional
data

Number of columns: 8 Here we are discussing about the
\emph{\textbf{Bulk} dataset}

\begin{quote}
\mbox{}%
\hypertarget{country}{%
\paragraph{Country:}\label{country}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{Factor} with 153-levels 
\item
  Holds the name of Countries for daily data
\item
  Eg.: Japan
\end{itemize}

\mbox{}%
\hypertarget{day}{%
\paragraph{Day:}\label{day}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{Factor} with 58-levels 
\item
  Holds days numbered from 1 upto the last day 
\item
  Eg.: for Jan 22nd, Day is 1, Jan 23rd, Day is 2 and so on..
\end{itemize}

\mbox{}%
\hypertarget{date}{%
\paragraph{Date:}\label{date}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{Factor} with 58-levels 
\item
  Holds dates in format \textbf{dd-mm-yyyy} and where individual level
  has the datatype \emph{Date} 
\item
  Eg.: 22-01-2020
\end{itemize}

\mbox{}%
\hypertarget{confirmed}{%
\paragraph{Confirmed:}\label{confirmed}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{num} 
\item
  Holds total number of confirm cases in a country, upto the given
  date/day 
\item
  Eg.: upto 01-02-2020, Japan reported 20 COVID-19 cases
\end{itemize}

\mbox{}%
\hypertarget{deaths}{%
\paragraph{Deaths:}\label{deaths}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{num} 
\item
  Holds total number of deaths in a country, upto the given date/day 
\item
  Eg.: upto 01-02-2020, Japan reported no Deaths
\end{itemize}

\mbox{}%
\hypertarget{recovered}{%
\paragraph{Recovered:}\label{recovered}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{num} 
\item
  Holds total number of recoveries in a county, upto the given date/day 
\item
  Eg.: upto 01-02-2020, Japan reported 1 Recoveries
\end{itemize}

\mbox{}%
\hypertarget{active.cases}{%
\paragraph{Active.Cases:}\label{active.cases}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{num} 
\item
  Holds total Confirmed cases, except Deaths \& Recoveries in a country,
  upto the given date/day 
\item
  Eg.: upto 01-02-2020, Japan had 19 Active cases
\end{itemize}

\mbox{}%
\hypertarget{closed.cases}{%
\paragraph{Closed.Cases:}\label{closed.cases}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{num} 
\item
  Holds total number of Recoveries or Deaths in a country, upto the
  given date/day 
\item
  Eg.: upto 01-02-2020, Japan had closed 1 COVID-19 case
\end{itemize}
\end{quote}

    \hypertarget{now-we-are-all-set-to-filter-out-china-from-this-dataset}{%
\paragraph{Now we are all set to filter out China from this
dataset!}\label{now-we-are-all-set-to-filter-out-china-from-this-dataset}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} filtering out the China}
\PY{n}{China.dataset} \PY{o}{=} \PY{n}{bulk}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Country}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{China\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}

\PY{c+c1}{\PYZsh{} World Pooled dataset (except china)}
\PY{n}{bulk} \PY{o}{=} \PY{n}{bulk}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{bulk}\PY{o}{\PYZdl{}}\PY{n}{Country}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{China\PYZsq{}}\PY{p}{,} \PY{n}{negate}\PY{o}{=}\PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]} \PY{c+c1}{\PYZsh{} updating bulk itself}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{head}\PY{p}{(}\PY{n}{China.dataset}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
  & Country & Day & Date & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases\\
\hline
	1741 & China      & 1          & 22-01-2020 &  104       & 0          &  0         &  104       &  0        \\
	1742 & China      & 2          & 23-01-2020 &  199       & 1          &  2         &  196       &  3        \\
	1743 & China      & 3          & 24-01-2020 &  371       & 2          &  5         &  364       &  7        \\
	1744 & China      & 4          & 25-01-2020 &  645       & 2          &  7         &  636       &  9        \\
	1745 & China      & 5          & 26-01-2020 & 1017       & 4          &  7         & 1006       & 11        \\
	1746 & China      & 6          & 27-01-2020 & 1454       & 6          & 13         & 1435       & 19        \\
\end{tabular}


    
     In the same manner, we create two datasets * 1st: that holds
\textbf{all} the data of all the countries except Hubei in China * 2nd:
that holds whole data categorized into four locations. These four
locations are: \textgreater{} 1. Diamond Princess \textgreater{} 2.
Hubei province (alone) same as Diamond Princess Cruise Ship
\textgreater{} 3. China alone data (Except Hubei province)
\textgreater{} 4. World (Except China), collectively

The 2nd type of dataset is very necessary because it consists of all the
outliers as well\ldots{} * Actually, here we can take them into
consideration because: \textgreater{} 1. Here we are comparing them with
the whole World's data collectively \textgreater{} 2. It's that kind of
MEDICAL Data, where outliers can not be ignored! In-fact this single
country and that ship are spreading the disease, rapidly. \textgreater{}
3. This 2nd dataset alone keeps track on the whole data, reported till
the last date

\begin{itemize}
\tightlist
\item
  We've already saved this dataset 
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{} Load both datewise\PYZhy{}datasets (world \PYZam{} FOUR)}
\PY{c+c1}{\PYZsh{} includes data of all the countries}
\PY{n}{all} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Notebooks/syllabus/static/pooled/countryWise\PYZus{}bulk\PYZus{}summary.csv\PYZsq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} includes data of four majour location}
\PY{n}{four} \PY{o}{=} \PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{Notebooks/syllabus/static/pooled/Four\PYZus{}dataset\PYZus{}locationWise.csv\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{63}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{str}\PY{p}{(}\PY{n}{all}\PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}

\PY{n+nf}{str}\PY{p}{(}\PY{n}{four}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
'data.frame':   8874 obs. of  8 variables:
 \$ Country     : Factor w/ 153 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 {\ldots}
 \$ Day         : int  1 2 3 4 5 6 7 8 9 10 {\ldots}
 \$ Date        : Factor w/ 58 levels "01-02-2020","01-03-2020",..: 41 43 45 47
49 51 53 55 57 58 {\ldots}
 \$ Confirmed   : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Deaths      : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Recovered   : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Active.Cases: int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Closed.Cases: int  0 0 0 0 0 0 0 0 0 0 {\ldots}


'data.frame':   232 obs. of  8 variables:
 \$ Location    : Factor w/ 4 levels "China","Diamond Princess",..: 3 3 3 3 3 3 3
3 3 3 {\ldots}
 \$ Day         : int  1 2 3 4 5 6 7 8 9 10 {\ldots}
 \$ Date        : Factor w/ 58 levels "01-02-2020","01-03-2020",..: 41 43 45 47
49 51 53 55 57 58 {\ldots}
 \$ Confirmed   : int  444 444 549 761 1058 1423 3554 3554 4903 5806 {\ldots}
 \$ Deaths      : int  17 17 24 40 52 76 125 125 162 204 {\ldots}
 \$ Recovered   : int  28 28 31 32 42 45 80 88 90 141 {\ldots}
 \$ Active.Cases: int  399 399 494 689 964 1302 3349 3341 4651 5461 {\ldots}
 \$ Closed.Cases: int  45 45 55 72 94 121 205 213 252 345 {\ldots}
    \end{Verbatim}

     In the \textbf{\emph{all dataset}}, everything is same as in `Bulk'
dataset

In the \textbf{\emph{four dataset}}:

\begin{quote}
\mbox{}%
\hypertarget{location}{%
\paragraph{Location:}\label{location}}

\begin{itemize}
\tightlist
\item
  Datatype: \textbf{Factor} with 4-levels 
\item
  Holds the name of Locations (as Countries in `Bulk') for daily data 
\item
  Levels: World, China, Hubei \& Diamond Princess Rest \textbf{7}
  columns are same as those of `Bulk' dataset
\end{itemize}
\end{quote}

    \hypertarget{lets-analyze-that-how-china-differ-from-rest-of-the-data-using-boxplots}{%
\subsubsection{Let's analyze that how China differ from rest of the data
using
Boxplots}\label{lets-analyze-that-how-china-differ-from-rest-of-the-data-using-boxplots}}

\hypertarget{why-boxplot-}{%
\paragraph{\texorpdfstring{Why Boxplot:-
}{Why Boxplot:-  }}\label{why-boxplot-}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  It's a single visualization that tells about many statistical
  quantifiers 
\item
  It's very easy to detect Outliers through boxplot 
\end{itemize}
\end{quote}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{86}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Initially we plot dataset with majour Locations}
\PY{n+nf}{options}\PY{p}{(}\PY{n}{repr.plot.width}\PY{o}{=}\PY{l+m}{16}\PY{p}{,} \PY{n}{repr.plot.height}\PY{o}{=}\PY{l+m}{8}\PY{p}{)}
\PY{n}{withChina}\PY{o}{\PYZlt{}\PYZhy{}}\PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{four}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{Day}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{Confirmed}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{n}{Day}\PY{p}{)}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{geom\PYZus{}boxplot}\PY{p}{(}\PY{n+nf}{aes}\PY{p}{(}\PY{n}{group}\PY{o}{=}\PY{n}{Day}\PY{p}{)}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{labs}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Including China\PYZdq{}}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme\PYZus{}classic}\PY{p}{(}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme}\PY{p}{(}
          \PY{n}{text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gill Sans\PYZdq{}}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.subtitle} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{25}\PY{p}{,} \PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Courier\PYZdq{}}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{12}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{)}
  \PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{n}{withChina}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]


    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_116_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     Here we get a continuous sequence of \textbf{outliers}, for roughly
upto 45 days Now, as per our previous analysis (through word-clouds and
mean-comparison, we assumed the China as this outlier) In order to Test
our hypothesis, let's plot China alone, as well as Rest of all data
except China 

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{94}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{options}\PY{p}{(}\PY{n}{repr.plot.width}\PY{o}{=}\PY{l+m}{16}\PY{p}{,} \PY{n}{repr.plot.height}\PY{o}{=}\PY{l+m}{8}\PY{p}{)}

\PY{n}{chinaAlone} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{four}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{four}\PY{o}{\PYZdl{}}\PY{n}{Location}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}}\PY{p}{,} \PY{n}{negate}\PY{o}{=}\PY{n+nb+bp}{F}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{Day}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{Confirmed}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{n}{Day}\PY{p}{)}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{n+nf}{aes}\PY{p}{(}\PY{n}{group}\PY{o}{=}\PY{n}{Day}\PY{p}{)}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{labs}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Only China\PYZdq{}}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme\PYZus{}classic}\PY{p}{(}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme}\PY{p}{(}
          \PY{n}{text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gill Sans\PYZdq{}}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.subtitle} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{25}\PY{p}{,} \PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Courier\PYZdq{}}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{12}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{)}
  \PY{p}{)}

\PY{n}{withoutChina} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{four}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{four}\PY{o}{\PYZdl{}}\PY{n}{Location}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}}\PY{p}{,} \PY{n}{negate}\PY{o}{=}\PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{Day}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{Confirmed}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{n}{Day}\PY{p}{)}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{geom\PYZus{}boxplot}\PY{p}{(}\PY{n+nf}{aes}\PY{p}{(}\PY{n}{group}\PY{o}{=}\PY{n}{Day}\PY{p}{)}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{labs}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Excluding China\PYZdq{}}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme\PYZus{}classic}\PY{p}{(}\PY{p}{)} \PY{o}{+}
  \PY{n+nf}{theme}\PY{p}{(}
          \PY{n}{text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gill Sans\PYZdq{}}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{plot.subtitle} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{25}\PY{p}{,} \PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Courier\PYZdq{}}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{12}\PY{p}{)}
          \PY{p}{,}\PY{n}{axis.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{)}
  \PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{n}{chinaAlone}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{n}{withoutChina}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]




    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_118_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_118_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     \#\#\#\# Comparing above 2 plots with our previous single plot of the
whole (4) data categorize, collectively:- 1. First box plots resembles
the sequence, that is far more similar to the Outliers' sequence 2.
Along with this, when we try plotting the whole data again, after
removing the China, we find that there is no outlier, at all

So, finally we can say that the \textbf{China is an outlier}, and hence
we'll study China, separately! 

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{96}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s view few of the rows in existing datasets}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{all}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{four}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
 Country & Day & Date & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases\\
\hline
	 Afghanistan & 1           & 22-01-2020  & 0           & 0           & 0           & 0           & 0          \\
	 Afghanistan & 2           & 23-01-2020  & 0           & 0           & 0           & 0           & 0          \\
	 Afghanistan & 3           & 24-01-2020  & 0           & 0           & 0           & 0           & 0          \\
	 Afghanistan & 4           & 25-01-2020  & 0           & 0           & 0           & 0           & 0          \\
	 Afghanistan & 5           & 26-01-2020  & 0           & 0           & 0           & 0           & 0          \\
	 Afghanistan & 6           & 27-01-2020  & 0           & 0           & 0           & 0           & 0          \\
\end{tabular}


    
    \begin{tabular}{r|llllllll}
 Location & Day & Date & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases\\
\hline
	 Hubei      & 1          & 22-01-2020 &  444       & 17         & 28         &  399       &  45       \\
	 Hubei      & 2          & 23-01-2020 &  444       & 17         & 28         &  399       &  45       \\
	 Hubei      & 3          & 24-01-2020 &  549       & 24         & 31         &  494       &  55       \\
	 Hubei      & 4          & 25-01-2020 &  761       & 40         & 32         &  689       &  72       \\
	 Hubei      & 5          & 26-01-2020 & 1058       & 52         & 42         &  964       &  94       \\
	 Hubei      & 6          & 27-01-2020 & 1423       & 76         & 45         & 1302       & 121       \\
\end{tabular}


    
     Now, as we aim to analyze the status of COVID-19 within next 10 days,
which means that we basically want to analyze the active or closed cases
within that time duration. But, as these 2 are just discrete figures and
hence can vary depending upon the Confirmed, Recovery \& Death cases It
means all these figures can vary dynamically So, in this situation,
finding any internal relation between the columns
Confirmed/Recovery/Death and Active/Closed cases ain't an easy task.
Now, in order to establish a relationship between these, the can take
\textbf{Rate of Increase} in Active/Closed cases

\begin{verbatim}
i.e. what percent (%) of Confirmed cases are Active/Closed, and which would simply be depend upon total Confirmed cases
\end{verbatim}

 Hence, before we move towards creating a suitable model for our problem
form available dataset, we'd have to do one last transformation, by
adding two more columns to our existing dataset i.e. 1. Active Cases(\%)
2. Closed Cases(\%) 

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} calculate the percent (using Confirmed cases as total)}
\PY{n}{percent} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{function}\PY{p}{(}\PY{n}{dfName}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n+nf}{get}\PY{p}{(}\PY{n}{dfName}\PY{p}{)} \PY{o}{\PYZhy{}\PYZgt{}} \PY{n}{df}
    \PY{n}{part} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
    
    \PY{n+nf}{for}\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
        \PY{n}{val} \PY{o}{=} \PY{n}{df}\PY{n}{[i}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{Active.Cases\PYZdq{}}\PY{n}{]}
        \PY{n}{Total} \PY{o}{=} \PY{n}{df}\PY{n}{[i}\PY{p}{,}\PY{l+s}{\PYZdq{}}\PY{l+s}{Confirmed\PYZdq{}}\PY{n}{]}
        
        
        \PY{n+nf}{if}\PY{p}{(}\PY{n}{i} \PY{o}{==} \PY{l+m}{1}\PY{p}{)}
            \PY{n+nf}{if}\PY{p}{(}\PY{n}{val}\PY{o}{==}\PY{l+m}{0}\PY{p}{)}
                \PY{n}{part} \PY{o}{=} \PY{l+m}{0}
            \PY{n}{else}
                \PY{n}{part} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{p}{(}\PY{n}{val}\PY{o}{*}\PY{l+m}{100}\PY{p}{)}\PY{o}{/}\PY{n}{Total}\PY{p}{)}
        \PY{n}{else}
            \PY{n+nf}{if}\PY{p}{(}\PY{n}{val}\PY{o}{==}\PY{l+m}{0}\PY{p}{)}
                \PY{n}{part} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{part}\PY{p}{,} \PY{l+m}{0}\PY{p}{)}
            \PY{n}{else}
                \PY{n}{part} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{c}\PY{p}{(}\PY{n}{part}\PY{p}{,} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{p}{(}\PY{n}{val}\PY{o}{*}\PY{l+m}{100}\PY{p}{)}\PY{o}{/}\PY{n}{Total}\PY{p}{)}\PY{p}{)}
    \PY{p}{\PYZcb{}}
        
    \PY{n+nf}{return}\PY{p}{(}\PY{n}{part}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} CASES \PYZhy{}\PYZgt{} percentage}
\PY{n}{four}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZsq{}}\PY{l+s}{percent\PYZus{}active\PYZsq{}} \PY{o}{=} \PY{n+nf}{percent}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{four\PYZdq{}}\PY{p}{)}     \PY{c+c1}{\PYZsh{} Active cases, out of every 100 Confirmed cases}
\PY{n}{four}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZsq{}}\PY{l+s}{percent\PYZus{}closed\PYZsq{}} \PY{o}{=} \PY{l+m}{100}\PY{o}{\PYZhy{}}\PY{n+nf}{percent}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{four\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} Closed cases, out of every 100 Confirmed cases}


\PY{n}{all}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZsq{}}\PY{l+s}{percent\PYZus{}active\PYZsq{}} \PY{o}{=} \PY{n+nf}{percent}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{all\PYZdq{}}\PY{p}{)}     \PY{c+c1}{\PYZsh{} Active cases, out of every 100 Confirmed cases}
\PY{n}{all}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZsq{}}\PY{l+s}{percent\PYZus{}closed\PYZsq{}} \PY{o}{=} \PY{l+m}{100}\PY{o}{\PYZhy{}}\PY{n+nf}{percent}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{all\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} Closed cases, out of every 100 Confirmed cases}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Look onto the structure whether the things are updated or not}
\PY{n+nf}{str}\PY{p}{(}\PY{n}{all}\PY{p}{)}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}

\PY{n+nf}{str}\PY{p}{(}\PY{n}{four}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
'data.frame':   8874 obs. of  10 variables:
 \$ Country       : Factor w/ 153 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1
{\ldots}
 \$ Day           : int  1 2 3 4 5 6 7 8 9 10 {\ldots}
 \$ Date          : Factor w/ 58 levels "01-02-2020","01-03-2020",..: 41 43 45 47
49 51 53 55 57 58 {\ldots}
 \$ Confirmed     : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Deaths        : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Recovered     : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Active.Cases  : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ Closed.Cases  : int  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ percent\_active: num  0 0 0 0 0 0 0 0 0 0 {\ldots}
 \$ percent\_closed: num  100 100 100 100 100 100 100 100 100 100 {\ldots}


'data.frame':   232 obs. of  10 variables:
 \$ Location      : Factor w/ 4 levels "China","Diamond Princess",..: 3 3 3 3 3 3
3 3 3 3 {\ldots}
 \$ Day           : int  1 2 3 4 5 6 7 8 9 10 {\ldots}
 \$ Date          : Factor w/ 58 levels "01-02-2020","01-03-2020",..: 41 43 45 47
49 51 53 55 57 58 {\ldots}
 \$ Confirmed     : int  444 444 549 761 1058 1423 3554 3554 4903 5806 {\ldots}
 \$ Deaths        : int  17 17 24 40 52 76 125 125 162 204 {\ldots}
 \$ Recovered     : int  28 28 31 32 42 45 80 88 90 141 {\ldots}
 \$ Active.Cases  : int  399 399 494 689 964 1302 3349 3341 4651 5461 {\ldots}
 \$ Closed.Cases  : int  45 45 55 72 94 121 205 213 252 345 {\ldots}
 \$ percent\_active: num  89.9 89.9 90 90.5 91.1 {\ldots}
 \$ percent\_closed: num  10.14 10.14 10.02 9.46 8.88 {\ldots}
    \end{Verbatim}

    \hypertarget{ok-everything-is-set.-now-we-can-go-for-themodel-creation}{%
\subsubsection{\texorpdfstring{\emph{OK! Everything is set. Now we can
go for themodel
creation\ldots{}}}{OK! Everything is set. Now we can go for themodel creation\ldots{}}}\label{ok-everything-is-set.-now-we-can-go-for-themodel-creation}}

    

    

    \hypertarget{modeling}{%
\subsection{Modeling:}\label{modeling}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  EXTRACTING CHINA
\item
  CHOOSING THE RIGHT ALGO.
\item
  DATA SPLITTING: Train-Test
\item
  ALGORITHMS
\item
  SVMK Regression
\item
  KNN Regression
\item
  Linear Regression
\item
  Polynomial Regression
\end{itemize}
\end{quote}

    \begin{itemize}
\tightlist
\item
  Now we have the data of all the different countries as well as the
  aggregate date-wise data of the whole world, too.
\item
  Also, we have data of some special locations, lying far away from the
  trend (say outliers) 
\item
  So, we have to decide that which Country, we are going to do our
  analysis

  \begin{itemize}
  \tightlist
  \item
    It can be chosen with the help of the following function
  \end{itemize}
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} extracting the desired dataset}
\PY{n}{extractDatases} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{function}\PY{p}{(}\PY{n}{region}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n+nf}{if}\PY{p}{(}\PY{n}{region} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{World\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Diamond Princess\PYZdq{}}\PY{p}{)}\PY{p}{)} \PY{p}{\PYZob{}}
    \PY{n}{temp} \PY{o}{=} \PY{n}{four}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{four}\PY{o}{\PYZdl{}}\PY{n}{Location}\PY{p}{,} \PY{n}{region}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}
    \PY{n+nf}{row.names}\PY{p}{(}\PY{n}{temp}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{p}{\PYZcb{}} \PY{n}{else} \PY{p}{\PYZob{}}
    \PY{n}{temp} \PY{o}{=} \PY{n}{all}\PY{n+nf}{[which}\PY{p}{(}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{all}\PY{o}{\PYZdl{}}\PY{n}{Country}\PY{p}{,} \PY{n}{region}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{n}{]}
    \PY{n+nf}{row.names}\PY{p}{(}\PY{n}{temp}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{p}{\PYZcb{}}

\PY{n+nf}{return}\PY{p}{(}\PY{n}{temp}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

     \#\#\# Extracting China

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} country i.e. to be used throughout the analysis}
\PY{n}{rName} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{China\PYZdq{}} \PY{c+c1}{\PYZsh{} without hubei}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} filtering out desired country/location }
\PY{n}{region1} \PY{o}{=} \PY{n+nf}{extractDatases}\PY{p}{(}\PY{n}{rName}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} so we are missing something, when we have outliers saperatly,}
    \PY{c+c1}{\PYZsh{} better is that we join Hubei data in China so that our Countries\PYZsq{} dataset don\PYZsq{}t have any vulnarability}

\PY{c+c1}{\PYZsh{} joining Hubei for complete data of china}
\PY{n}{region2} \PY{o}{=} \PY{n+nf}{extractDatases}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Hubei\PYZdq{}}\PY{p}{)}
\PY{n}{region} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}\PY{n}{region1}\PY{n}{[}\PY{p}{,}\PY{l+m}{1}\PY{o}{:}\PY{l+m}{3}\PY{n}{]}\PY{p}{,} \PY{n}{region1}\PY{n}{[}\PY{p}{,}\PY{l+m}{4}\PY{o}{:}\PY{l+m}{8}\PY{n}{]}\PY{o}{+}\PY{n}{region2}\PY{n}{[}\PY{p}{,}\PY{l+m}{4}\PY{o}{:}\PY{l+m}{8}\PY{n}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} filtering out desired country/location }

\PY{n}{region}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZsq{}}\PY{l+s}{percent\PYZus{}active\PYZsq{}} \PY{o}{=} \PY{n+nf}{percent}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{region\PYZdq{}}\PY{p}{)}     \PY{c+c1}{\PYZsh{} Active cases, out of every 100 Confirmed cases}
\PY{n}{region}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZsq{}}\PY{l+s}{percent\PYZus{}closed\PYZsq{}} \PY{o}{=} \PY{l+m}{100}\PY{o}{\PYZhy{}}\PY{n+nf}{percent}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{region\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} Closed cases, out of every 100 Confirmed cases}

\PY{n+nf}{head}\PY{p}{(}\PY{n}{region}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllllll}
 Country & Day & Date & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases & percent\_active & percent\_closed\\
\hline
	 China      & 1          & 22-01-2020 &  548       & 17         & 28         &  503       &  45        & 91.78832   & 8.211679  \\
	 China      & 2          & 23-01-2020 &  643       & 18         & 30         &  595       &  48        & 92.53499   & 7.465008  \\
	 China      & 3          & 24-01-2020 &  920       & 26         & 36         &  858       &  62        & 93.26087   & 6.739130  \\
	 China      & 4          & 25-01-2020 & 1406       & 42         & 39         & 1325       &  81        & 94.23898   & 5.761024  \\
	 China      & 5          & 26-01-2020 & 2075       & 56         & 49         & 1970       & 105        & 94.93976   & 5.060241  \\
	 China      & 6          & 27-01-2020 & 2877       & 82         & 58         & 2737       & 140        & 95.13382   & 4.866180  \\
\end{tabular}


    
     Because, it is the dataset of China, the \textbf{Country} column is not
necessary. Simillarly, there is no need of \textbf{Date}, when we have
Day

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{region}\PY{o}{=}\PY{n}{region}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+m}{\PYZhy{}1}\PY{p}{,} \PY{l+m}{\PYZhy{}3}\PY{p}{)}\PY{n}{]}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{region}\PY{p}{,} \PY{l+m}{10}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
 Day & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases & percent\_active & percent\_closed\\
\hline
	  1       &  548     &  17      &  28      &  503     &  45      & 91.78832 & 8.211679\\
	  2       &  643     &  18      &  30      &  595     &  48      & 92.53499 & 7.465008\\
	  3       &  920     &  26      &  36      &  858     &  62      & 93.26087 & 6.739130\\
	  4       & 1406     &  42      &  39      & 1325     &  81      & 94.23898 & 5.761024\\
	  5       & 2075     &  56      &  49      & 1970     & 105      & 94.93976 & 5.060241\\
	  6       & 2877     &  82      &  58      & 2737     & 140      & 95.13382 & 4.866180\\
	  7       & 5509     & 131      & 101      & 5277     & 232      & 95.78871 & 4.211291\\
	  8       & 6087     & 133      & 120      & 5834     & 253      & 95.84360 & 4.156399\\
	  9       & 8141     & 171      & 135      & 7835     & 306      & 96.24125 & 3.758752\\
	 10       & 9802     & 213      & 214      & 9375     & 427      & 95.64375 & 4.356254\\
\end{tabular}


    
    Now our Dataset is ready for modling

    \hypertarget{choosing-the-right-algo.}{%
\subsubsection{Choosing the Right
Algo.}\label{choosing-the-right-algo.}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{127}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} setting the theme}
\PY{n+nf}{theme\PYZus{}set}\PY{p}{(}\PY{n+nf}{theme\PYZus{}classic}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{c+c1}{\PYZsh{} setting plot size}
\PY{n+nf}{options}\PY{p}{(}\PY{n}{repr.plot.width}\PY{o}{=}\PY{l+m}{8}\PY{p}{,} \PY{n}{repr.plot.height}\PY{o}{=}\PY{l+m}{8}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

     We are working onto a \textbf{Predictive Data Analysis} (as discussed
earlier) project. So, in this situation, we can choose between two types
of predictive algorithms, based on our objective. These 2 categories
are:-

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Classification
\item
  Regression 
\end{enumerate}

    To estimate the future status of COVID-19 cases in China - we'll be
using Regression

     \#\#\# * Why Regression and not Classification? * Classification: * It
is used to categorize the given data-points, there are discrete
(i.e.~selective) number of the categories. * Every new data point (for
which the estimation is being made) must belong to any of the existing
class/category, only. * Regression: * It predicts the new possible
outcome, based on the earlier trend. * There is NO such necessity for
the predicted value that it must be one among the given set of
categories.

We want to calculate that what might be the upcoming figure for Active
Cases' \% in China, particularly; that ain't be limited values. That's
why, Regression has to be used!! 

     We will compare mainly 3 regression algorithms to predict the required
value from rest all of the columns. Then based onto the accuracy of the
prediction using different columns, we'll choose the column that has to
be used for prediction.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{120}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}\PYZsh{} REGRASSIONs}

\PY{c+c1}{\PYZsh{} converting from Factor}
\PY{n}{region}\PY{o}{\PYZdl{}}\PY{n}{Day} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n+nf}{as.character}\PY{p}{(}\PY{n}{region}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{)}\PY{p}{)}

\PY{n}{x} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{region}\PY{n}{[}\PY{p}{,}\PY{l+m}{1}\PY{o}{:}\PY{l+m}{6}\PY{p}{,} \PY{l+m}{8}\PY{n}{]}\PY{p}{)}
\PY{n}{y} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{region}\PY{n}{[}\PY{p}{,}\PY{l+m}{7}\PY{n}{]}\PY{p}{)}

\PY{n}{end} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZbs{}n\PYZbs{}n\PYZbs{}n\PYZdq{}}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}nLinear Regression:\PYZbs{}n\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} fit model}
\PY{n}{fit} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{percent\PYZus{}active}\PY{o}{\PYZti{}}\PY{n}{.,} \PY{n}{region}\PY{p}{)}
\PY{c+c1}{\PYZsh{} summarize the fit}
\PY{n+nf}{summary}\PY{p}{(}\PY{n}{fit}\PY{p}{)}
\PY{c+c1}{\PYZsh{} make predictions}
\PY{n}{predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{region}\PY{p}{)}
\PY{c+c1}{\PYZsh{} summarize accuracy}
\PY{n}{mse} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{sqrt}\PY{p}{(}\PY{n+nf}{mean}\PY{p}{(}\PY{p}{(}\PY{n}{region}\PY{o}{\PYZdl{}}\PY{n}{percent\PYZus{}active} \PY{o}{\PYZhy{}} \PY{n}{predictions}\PY{p}{)}\PY{n}{\PYZca{}2}\PY{p}{)}\PY{p}{)}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{RMSE: \PYZdq{}}\PY{p}{,} \PY{n}{mse}\PY{p}{)}



\PY{n+nf}{cat}\PY{p}{(}\PY{n}{end}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{k\PYZhy{}Nearest Neighbors:\PYZbs{}n\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} load the libraries}
\PY{c+c1}{\PYZsh{} fit model}
\PY{n}{fit} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{knnreg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{l+m}{3}\PY{p}{)}
\PY{c+c1}{\PYZsh{} summarize the fit}
\PY{n+nf}{summary}\PY{p}{(}\PY{n}{fit}\PY{p}{)}
\PY{c+c1}{\PYZsh{} make predictions}
\PY{n}{predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{x}\PY{p}{)}
\PY{c+c1}{\PYZsh{} summarize accuracy}
\PY{n}{mse} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{sqrt}\PY{p}{(}\PY{n+nf}{mean}\PY{p}{(}\PY{p}{(}\PY{n}{y} \PY{o}{\PYZhy{}} \PY{n}{predictions}\PY{p}{)}\PY{n}{\PYZca{}2}\PY{p}{)}\PY{p}{)}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{RMSE: \PYZdq{}}\PY{p}{,} \PY{n}{mse}\PY{p}{)}



\PY{n+nf}{cat}\PY{p}{(}\PY{n}{end}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{Support Vector Machine:\PYZbs{}n\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZbs{}n\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} fit model}
\PY{n}{fit} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ksvm}\PY{p}{(}\PY{n}{percent\PYZus{}active}\PY{o}{\PYZti{}}\PY{n}{.,} \PY{n}{region}\PY{p}{,} \PY{n}{kernel}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{rbfdot\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} summarize the fit}
\PY{n+nf}{summary}\PY{p}{(}\PY{n}{fit}\PY{p}{)}
\PY{c+c1}{\PYZsh{} make predictions}
\PY{n}{predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{region}\PY{p}{)}
\PY{c+c1}{\PYZsh{} summarize accuracy}
\PY{n}{mse} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{sqrt}\PY{p}{(}\PY{n+nf}{mean}\PY{p}{(}\PY{p}{(}\PY{n}{y} \PY{o}{\PYZhy{}} \PY{n}{predictions}\PY{p}{)}\PY{n}{\PYZca{}2}\PY{p}{)}\PY{p}{)}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{RMSE: \PYZdq{}}\PY{p}{,} \PY{n}{mse}\PY{p}{)}




\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]


Linear Regression:
------------------
    \end{Verbatim}

    
    \begin{verbatim}

Call:
lm(formula = percent_active ~ ., data = region)

Residuals:
       Min         1Q     Median         3Q        Max 
-1.142e-13 -5.385e-15 -1.048e-15  7.607e-15  5.031e-14 

Coefficients: (2 not defined because of singularities)
                 Estimate Std. Error    t value Pr(>|t|)    
(Intercept)     1.000e+02  2.119e-14  4.718e+15  < 2e-16 ***
Day             6.411e-15  1.560e-15  4.109e+00 0.000141 ***
Confirmed      -1.740e-18  9.716e-19 -1.791e+00 0.079073 .  
Deaths          2.854e-17  2.979e-17  9.580e-01 0.342505    
Recovered       1.375e-17  4.069e-18  3.379e+00 0.001385 ** 
Active.Cases           NA         NA         NA       NA    
Closed.Cases           NA         NA         NA       NA    
percent_closed -1.000e+00  3.169e-15 -3.155e+14  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.061e-14 on 52 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:      1 
F-statistic: 2.615e+31 on 5 and 52 DF,  p-value: < 2.2e-16

    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
RMSE:  4.812696e-14

\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#


 k-Nearest Neighbors:
--------------------
    \end{Verbatim}

    
    \begin{verbatim}
        Length Class  Mode   
learn   2      -none- list   
k       1      -none- numeric
theDots 0      -none- list   
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
RMSE:  0.5710865

\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#


 Support Vector Machine:
-----------------------
    \end{Verbatim}

    
    \begin{verbatim}
Length  Class   Mode 
     1   ksvm     S4 
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
RMSE:  2.820561
    \end{Verbatim}

     From the summary of different regression algorithms above, we find that
Day column should be given the priority.

As inn the summary of linear regression:

\begin{verbatim}
                  | Estimate Std.|  Error    |  t value  |  Pr(>|t|)  
     -------------|--------------|-----------|-----------|-----------
     (Intercept)  |  1.000e+02   | 1.202e-14 | 8.319e+15 |   < 2e-16  ***
     Day          |  5.221e-15   | 1.270e-15 | 4.112e+00 |  0.000140  ***
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Though, Active Case(\%) can easily be calculated if we know Closed
  Case(\%) or data About Confirmed/Death/Recovered cases data

  \begin{itemize}
  \tightlist
  \item
    but we actually don't have any of these things, because once we know
    that we'd have the future estimate as well.
  \item
    and won't even this whole analysis. 
  \end{itemize}
\item
  So, finally we know that we should choose \textbf{Days} for Active
  Case(\%). 
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{137}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualizing the available data as a scatter plot to see how the Active Cases(\PYZpc{}) in China has varied over days, since 22nd January, 2020}

\PY{c+c1}{\PYZsh{} Day vs Active Cases(\PYZpc{})}
\PY{n}{region.scatter.plot} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{region}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{x} \PY{o}{=} \PY{n}{region}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{region}\PY{o}{\PYZdl{}}\PY{n}{percent\PYZus{}active}\PY{p}{)}\PY{p}{)} \PY{o}{+}
                        \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
                        \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{)} \PY{o}{+}
                        \PY{n+nf}{theme}\PY{p}{(}
                              \PY{n}{text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gill Sans\PYZdq{}}\PY{p}{)}
                              \PY{p}{,}\PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
                              \PY{p}{,}\PY{n}{plot.subtitle} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{25}\PY{p}{,} \PY{n}{family} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Courier\PYZdq{}}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{,} \PY{n}{hjust} \PY{o}{=} \PY{l+m}{0.5}\PY{p}{)}
                              \PY{p}{,}\PY{n}{axis.text} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{12}\PY{p}{)}
                              \PY{p}{,}\PY{n}{axis.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{)}
                              \PY{p}{)}
              
\PY{n}{region.scatter.plot}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_147_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     From the above visualization, it's clear that on an average, the active
case percentage has kept on decreasing over the days

Now we'll \textbf{split} our China dataset for \emph{training(80\%) \&
testing(20\%)}

     \#\#\# Data Splitting: train-test

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{set.seed}\PY{p}{(}\PY{l+m}{20}\PY{p}{)} \PY{c+c1}{\PYZsh{} generages same set of random sample every time}

\PY{n}{training.samples} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{region}\PY{o}{\PYZdl{}}\PY{n}{Day} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}}
  \PY{n+nf}{createDataPartition}\PY{p}{(}\PY{n}{p} \PY{o}{=} \PY{l+m}{0.8}\PY{p}{,} \PY{n}{list} \PY{o}{=} \PY{k+kc}{FALSE}\PY{p}{)}

\PY{n}{train.data}  \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{region}\PY{n}{[training.samples}\PY{p}{,} \PY{n}{]}
\PY{n}{test.data} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{region}\PY{n}{[}\PY{o}{\PYZhy{}}\PY{n}{training.samples}\PY{p}{,} \PY{n}{]}

\PY{c+c1}{\PYZsh{} Dimentions of the splitted datasets}
\PY{n+nf}{dim}\PY{p}{(}\PY{n}{train.data}\PY{p}{)}
\PY{n+nf}{dim}\PY{p}{(}\PY{n}{test.data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{enumerate*}
\item 48
\item 8
\end{enumerate*}


    
    \begin{enumerate*}
\item 10
\item 8
\end{enumerate*}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{131}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{head}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{l+m}{3}\PY{p}{)}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{test.data}\PY{p}{,} \PY{l+m}{3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
 Day & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases & percent\_active & percent\_closed\\
\hline
	 1        & 548      & 17       & 28       & 503      & 45       & 91.78832 & 8.211679\\
	 2        & 643      & 18       & 30       & 595      & 48       & 92.53499 & 7.465008\\
	 3        & 920      & 26       & 36       & 858      & 62       & 93.26087 & 6.739130\\
\end{tabular}


    
    \begin{tabular}{r|llllllll}
  & Day & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases & percent\_active & percent\_closed\\
\hline
	4 &  4       &  1406    &  42      &   39     &  1325    &   81     & 94.23898 & 5.761024\\
	13 & 13       & 19716    & 425      &  615     & 18676    & 1040     & 94.72510 & 5.274904\\
	15 & 15       & 27440    & 563      & 1115     & 25762    & 1678     & 93.88484 & 6.115160\\
\end{tabular}


    
    

    \hypertarget{selection-of-an-algorithm}{%
\subsubsection{Selection of an
algorithm}\label{selection-of-an-algorithm}}

As our training \& testing datasets are ready, now we have to select the
right regression algorithm to train our model

For this, we will compare four regression algorithms i.e.~1. Support
Vector Machines Regression 2. k-Nearest Neighbor Regression 3. Linear
Regression 4. Polynomial Regression

 \#\#\# What should be compared? * Errors (should be minimized) *
Accuracy (should be maximized) * R-Squared (R2) * How perfectly the
model fits while testing (as in the graphs) etc.. 

    

    \hypertarget{svmk-regression}{%
\subsubsection{1. SVMK Regression}\label{svmk-regression}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{132}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} model}
\PY{n}{fit.svmk} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ksvm}\PY{p}{(}\PY{n}{percent\PYZus{}active}\PY{o}{\PYZti{}}\PY{n}{Day}\PY{p}{,} \PY{n}{train.data}\PY{p}{,} \PY{n}{kernel}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{rbfdot\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{}summary(fit.svmk)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{133}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{fit.svmk} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{train.data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{134}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Model performance}
\PY{n}{svm.predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
  \PY{n}{RMSE} \PY{o}{=} \PY{n+nf}{RMSE}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{train.data}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{)}\PY{p}{,}
  \PY{n}{R2} \PY{o}{=} \PY{n+nf}{R2}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{train.data}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{)}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{135}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svmk.trained} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(} \PY{c+c1}{\PYZsh{} Prediction for training data}
            \PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.svmk}\PY{p}{,} \PY{n}{train.data}\PY{p}{)}
          \PY{p}{)}

\PY{n}{svmk.tested} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}  \PY{c+c1}{\PYZsh{} Prediction for tested data}
            \PY{n}{test.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.svmk}\PY{p}{,} \PY{n}{test.data}\PY{p}{)}
         \PY{p}{)}


\PY{n+nf}{tail}\PY{p}{(}\PY{n}{svmk.trained}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{svmk.tested}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	53 & 53        & 14.972153 & 17.26605 \\
	55 & 55        & 12.224649 & 13.81184 \\
	56 & 56        & 11.140171 & 12.97371 \\
	57 & 57        &  9.995931 & 13.09887 \\
	58 & 58        &  9.084860 & 14.37292 \\
\end{tabular}


    
    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	39 & 39       & 46.87610 & 49.87923\\
	41 & 41       & 40.39133 & 43.38354\\
	47 & 47       & 25.15992 & 28.07431\\
	50 & 50       & 19.91572 & 23.13298\\
	54 & 54       & 13.31185 & 15.34209\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{142}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualizations}

\PY{n}{svmk.trainer} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}smooth}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{svmk.trained}\PY{p}{,} \PY{n}{method}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{loess\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{0}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}line}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{svmk.trained}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZsh{}3366fe\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{1}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTraining plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)} 

\PY{n}{svmk.tester} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{test.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}smooth}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{svmk.tested}\PY{p}{,} \PY{n}{method}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{loess\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{0}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}line}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{svmk.tested}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZsh{}3366fe\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{1}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTesting plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{143}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}  Plotting}
\PY{n}{svmk.trainer}
\PY{n}{svmk.tester}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_161_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_161_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    

     \#\#\# 2. KNN Regression

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{144}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{x} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{l+m}{1}\PY{n}{]}\PY{p}{)}
\PY{n}{y} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{l+m}{7}\PY{n}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} fit model}
\PY{n}{fit.knn} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{knnreg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{l+m}{3}\PY{p}{)}
\PY{c+c1}{\PYZsh{}summary(fit.knn)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{145}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{fit.knn} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{x}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{146}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{knn.predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
  \PY{n}{RMSE} \PY{o}{=} \PY{n+nf}{RMSE}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{x}\PY{p}{)}\PY{p}{,}
  \PY{n}{R2} \PY{o}{=} \PY{n+nf}{R2}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{x}\PY{p}{)}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{147}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{knn.trained} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(} \PY{c+c1}{\PYZsh{} Prediction for training data}
            \PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.knn}\PY{p}{,} \PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{l+m}{1}\PY{n}{]}\PY{p}{)}\PY{p}{)}
          \PY{p}{)}

\PY{n}{knn.tested} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}  \PY{c+c1}{\PYZsh{} Prediction for tested data}
            \PY{n}{test.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.knn}\PY{p}{,} \PY{n+nf}{as.matrix}\PY{p}{(}\PY{n}{test.data}\PY{n}{[}\PY{p}{,}\PY{l+m}{1}\PY{n}{]}\PY{p}{)}\PY{p}{)}
         \PY{p}{)}


\PY{n+nf}{tail}\PY{p}{(}\PY{n}{knn.trained}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{knn.tested}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	53 & 53        & 14.972153 & 15.57997 \\
	55 & 55        & 12.224649 & 12.08323 \\
	56 & 56        & 11.140171 & 11.12025 \\
	57 & 57        &  9.995931 & 10.07365 \\
	58 & 58        &  9.084860 & 10.07365 \\
\end{tabular}


    
    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	39 & 39       & 46.87610 & 49.56913\\
	41 & 41       & 40.39133 & 38.31875\\
	47 & 47       & 25.15992 & 25.48533\\
	50 & 50       & 19.91572 & 20.06390\\
	54 & 54       & 13.31185 & 13.77505\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{148}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualizations}
\PY{n}{knn.trainer} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}smooth}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{knn.tested}\PY{p}{,} \PY{n}{method}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{loess\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{0}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}line}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{knn.trained}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZsh{}3366fe\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{1}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTraining plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)} 

\PY{n}{knn.tester} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{test.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}smooth}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{knn.tested}\PY{p}{,} \PY{n}{method}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{loess\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{0}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}line}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{knn.tested}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZsh{}3366fe\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m}{1}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTesting plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{149}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plotting}
\PY{n}{knn.trainer}
\PY{n}{knn.tester}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_169_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_169_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    

    \hypertarget{linear-regression}{%
\subsubsection{3. Linear Regression}\label{linear-regression}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{150}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} building linear model}
\PY{n}{fit.lm} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{Day} \PY{o}{\PYZti{}} \PY{n}{percent\PYZus{}active}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train.data}\PY{p}{)}
\PY{c+c1}{\PYZsh{}summary(fit.lm)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{151}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Predicting}
\PY{n}{predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{fit.lm} \PY{o}{\PYZpc{}\PYZgt{}\PYZpc{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{train.data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{152}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Model performance}
\PY{n}{lm.predictions} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
  \PY{n}{RMSE} \PY{o}{=} \PY{n+nf}{RMSE}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{train.data}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{)}\PY{p}{,}
  \PY{n}{R2} \PY{o}{=} \PY{n+nf}{R2}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{train.data}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{)}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{153}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lm.trained} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(} \PY{c+c1}{\PYZsh{} Prediction for training data}
            \PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.lm}\PY{p}{,} \PY{n}{train.data}\PY{p}{)}
          \PY{p}{)}

\PY{n}{lm.tested} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}  \PY{c+c1}{\PYZsh{} Prediction for tested data}
            \PY{n}{test.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.lm}\PY{p}{,} \PY{n}{test.data}\PY{p}{)}
         \PY{p}{)}


\PY{n+nf}{tail}\PY{p}{(}\PY{n}{lm.trained}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{lm.tested}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	53 & 53        & 14.972153 & 54.83990 \\
	55 & 55        & 12.224649 & 56.27379 \\
	56 & 56        & 11.140171 & 56.83977 \\
	57 & 57        &  9.995931 & 57.43693 \\
	58 & 58        &  9.084860 & 57.91241 \\
\end{tabular}


    
    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	39 & 39       & 46.87610 & 38.18960\\
	41 & 41       & 40.39133 & 41.57392\\
	47 & 47       & 25.15992 & 49.52302\\
	50 & 50       & 19.91572 & 52.25991\\
	54 & 54       & 13.31185 & 55.70639\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{154}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualizations}
\PY{n}{lm.trainer} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{stat\PYZus{}smooth}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{lm}\PY{p}{,} \PY{n}{formula} \PY{o}{=} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n}{x}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} linear function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTraining plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)} 

\PY{n}{lm.tester} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{test.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{stat\PYZus{}smooth}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{lm}\PY{p}{,} \PY{n}{formula} \PY{o}{=} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n}{x}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} linear function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTesting plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{155}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plotting}
\PY{n}{lm.trainer}
\PY{n}{lm.tester}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_177_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_177_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    

    \hypertarget{polynomial-regression}{%
\subsubsection{4. Polynomial regression}\label{polynomial-regression}}

    Checking for the best degree..

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Model performance}
\PY{n}{plm.predictions} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}
  \PY{n}{Degree} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
  \PY{n}{RMSE} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
  \PY{n}{RSE} \PY{o}{=} \PY{k+kc}{NULL}\PY{p}{,}
  \PY{n}{R2} \PY{o}{=} \PY{k+kc}{NULL}
\PY{p}{)}


\PY{n+nf}{for}\PY{p}{(}\PY{n}{deg} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{l+m}{20}\PY{p}{)}\PY{p}{\PYZob{}}
    
    \PY{c+c1}{\PYZsh{} building polynomial model}
    \PY{n}{fit.plm} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{percent\PYZus{}active} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train.data}\PY{p}{)}
    \PY{c+c1}{\PYZsh{}summary(fit.plm)}

    
    \PY{c+c1}{\PYZsh{}Residual Standard error (Like Standard Deviation)}
    \PY{n}{k}\PY{o}{=}\PY{n+nf}{length}\PY{p}{(}\PY{n}{fit.plm}\PY{o}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{)}\PY{l+m}{\PYZhy{}1}
    \PY{c+c1}{\PYZsh{}Multiple R\PYZhy{}Squared (Coefficient of Determination)}
    \PY{n}{SSyy}\PY{o}{=}\PY{n+nf}{sum}\PY{p}{(}\PY{p}{(}\PY{n}{train.data}\PY{o}{\PYZdl{}}\PY{n}{percent\PYZus{}active}\PY{o}{\PYZhy{}}\PY{n+nf}{mean}\PY{p}{(}\PY{n}{train.data}\PY{o}{\PYZdl{}}\PY{n}{percent\PYZus{}active}\PY{p}{)}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m}{2}\PY{p}{)}
    
    \PY{n}{SSE}\PY{o}{=}\PY{n+nf}{sum}\PY{p}{(}\PY{n}{fit.plm}\PY{o}{\PYZdl{}}\PY{n}{residuals}\PY{o}{*}\PY{o}{*}\PY{l+m}{2}\PY{p}{)}
    \PY{n}{n}\PY{o}{=}\PY{n+nf}{length}\PY{p}{(}\PY{n}{fit.plm}\PY{o}{\PYZdl{}}\PY{n}{residuals}\PY{p}{)}
    
    
    \PY{c+c1}{\PYZsh{} final}
    \PY{n}{rmse} \PY{o}{=} \PY{n+nf}{sqrt}\PY{p}{(}\PY{n}{SSE}\PY{o}{/}\PY{p}{(}\PY{n}{n}\PY{l+m}{\PYZhy{}1}\PY{p}{)}\PY{p}{)}
    \PY{n}{rse} \PY{o}{=} \PY{n+nf}{sqrt}\PY{p}{(}\PY{n}{SSE}\PY{o}{/}\PY{p}{(}\PY{n}{n}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{l+m}{1}\PY{o}{+}\PY{n}{k}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{}Residual Standard Error}
    \PY{n}{r2} \PY{o}{=} \PY{p}{(}\PY{n}{SSyy}\PY{o}{\PYZhy{}}\PY{n}{SSE}\PY{p}{)}\PY{o}{/}\PY{n}{SSyy}
    
    \PY{n}{temp} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
                        \PY{n}{Degree} \PY{o}{=} \PY{n}{deg}\PY{p}{,}
                        \PY{n}{RMSE} \PY{o}{=} \PY{n}{rmse}\PY{p}{,}
                        \PY{n}{RSE} \PY{o}{=} \PY{n}{rse}\PY{p}{,}
                        \PY{n}{R2} \PY{o}{=} \PY{n}{r2}
                      \PY{p}{)}
    
    \PY{n}{plm.predictions} \PY{o}{=} \PY{n+nf}{rbind}\PY{p}{(}\PY{n}{plm.predictions}\PY{p}{,} \PY{n}{temp}\PY{p}{)}
\PY{p}{\PYZcb{}}

\PY{n}{plm.predictions}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llll}
 Degree & RMSE & RSE & R2\\
\hline
	  1        & 9.1213834 & 9.2199958 & 0.9131809\\
	  2        & 4.6663640 & 4.7689337 & 0.9772778\\
	  3        & 2.2460160 & 2.3213223 & 0.9947360\\
	  4        & 1.2378209 & 1.2941140 & 0.9984011\\
	  5        & 1.2360031 & 1.3075064 & 0.9984058\\
	  6        & 0.7801015 & 0.8352339 & 0.9993650\\
	  7        & 0.7221723 & 0.7828161 & 0.9994558\\
	  8        & 0.6092638 & 0.6688397 & 0.9996126\\
	  9        & 0.5836966 & 0.6491489 & 0.9996445\\
	 10        & 0.5823322 & 0.6563249 & 0.9996461\\
	 11        & 0.5819927 & 0.6649901 & 0.9996465\\
	 12        & 0.5591038 & 0.6478991 & 0.9996738\\
	 13        & 0.5591038 & 0.6573579 & 0.9996738\\
	 14        & 0.5386723 & 0.6428603 & 0.9996972\\
	 15        & 0.5386723 & 0.6528277 & 0.9996972\\
	 16        & 0.5051696 & 0.6220214 & 0.9997337\\
	 17        & 0.5051696 & 0.6323034 & 0.9997337\\
	 18        & 0.4912791 & 0.6254293 & 0.9997481\\
	 19        & 0.4912791 & 0.6364997 & 0.9997481\\
	 20        & 0.4912791 & 0.6481795 & 0.9997481\\
\end{tabular}


    
    Form above, at around Degree 16, model attains R-Squared score =
0.999733, as well as the RMSE is also very low So we'd try taking degree
= 16

At \textbf{Degree = 16} \textgreater{} * R2 = 0.999733 \textgreater{} *
RMSE = 0.5051696

 So, taking degree of polynomial regression as \textbf{16}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{deg} \PY{o}{=} \PY{l+m}{16}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} building polynomial model}
\PY{n}{fit.plm} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{percent\PYZus{}active} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train.data}\PY{p}{)}
\PY{c+c1}{\PYZsh{}summary(fit.plm)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plm.trained} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(} \PY{c+c1}{\PYZsh{} Prediction for training data}
            \PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{train.data}\PY{p}{)}  \PY{c+c1}{\PYZsh{} predicting the values}
          \PY{p}{)}

\PY{n}{plm.tested} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}  \PY{c+c1}{\PYZsh{} Prediction for tested data}
            \PY{n}{test.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{test.data}\PY{p}{)}   \PY{c+c1}{\PYZsh{} predicting the values}
         \PY{p}{)}


\PY{n+nf}{tail}\PY{p}{(}\PY{n}{plm.trained}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{plm.tested}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	53 & 53        & 14.972153 & 14.966792\\
	55 & 55        & 12.224649 & 12.244624\\
	56 & 56        & 11.140171 & 11.129915\\
	57 & 57        &  9.995931 & 10.013176\\
	58 & 58        &  9.084860 &  9.076924\\
\end{tabular}


    
    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	39 & 39       & 46.87610 & 47.44498\\
	41 & 41       & 40.39133 & 40.45985\\
	47 & 47       & 25.15992 & 25.26067\\
	50 & 50       & 19.91572 & 20.17564\\
	54 & 54       & 13.31185 & 13.49354\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Visualizations of the predictions for Training as well as Testing datasets to see fit}
\PY{n}{plm.trainer} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{stat\PYZus{}smooth}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{lm}\PY{p}{,} \PY{n}{formula} \PY{o}{=} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTraining plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)} 

\PY{n}{plm.tester} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{test.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{stat\PYZus{}smooth}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{lm}\PY{p}{,} \PY{n}{formula} \PY{o}{=} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTesting plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Plotting}
\PY{n}{plm.trainer}
\PY{n}{plm.tester}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_187_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_187_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     So we can see, here our model fits best for a polynomial regression
having degree = 16

\begin{quote}
We already have the data of \textbf{Day 59: i.e.~8.285436} To finalize
the model, we will perform a final testing by predicting the Active
Cases(\%) for Day: 59, 60, 61
\end{quote}

    Creating A temporary dataset for this prediction

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Available data for 59th day (i.e. 20\PYZhy{}03\PYZhy{}2020)}
\PY{n}{temp.test} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}
                        \PY{n}{Day} \PY{o}{=} \PY{l+m}{59}\PY{o}{:}\PY{l+m}{61}\PY{p}{,}
                        \PY{n}{Confirmed} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{81251}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}\PY{p}{,}
                        \PY{n}{Deaths} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{3253}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}\PY{p}{,}
                        \PY{n}{Recovered} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{71266}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}\PY{p}{,}
                        \PY{n}{Active.Cases} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{6732}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}\PY{p}{,}
                        \PY{n}{Closed.Cases} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{74519}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}\PY{p}{,}
                        \PY{n}{percent\PYZus{}active} \PY{o}{=}  \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{8.285436}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}\PY{p}{,}
                        \PY{n}{percent\PYZus{}closed} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{l+m}{91.7145}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{,} \PY{k+kc}{NaN}\PY{p}{)}
                     \PY{p}{)}

\PY{n}{temp.test}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
 Day & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases & percent\_active & percent\_closed\\
\hline
	 59       & 81251    & 3253     & 71266    & 6732     & 74519    & 8.285436 & 91.7145 \\
	 60       &   NaN    &  NaN     &   NaN    &  NaN     &   NaN    &      NaN &     NaN \\
	 61       &   NaN    &  NaN     &   NaN    &  NaN     &   NaN    &      NaN &     NaN \\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Now, we\PYZsq{}ll find the Active case(\PYZpc{}) from all the four algorithms}
\PY{n}{temp.required} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{temp.test}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+m}{1}\PY{p}{,} \PY{l+m}{7}\PY{p}{)}\PY{n}{]}
\PY{n}{temp.required}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZdq{}}\PY{l+s}{Polynomial Model\PYZdq{}} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{temp.test}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{temp.required}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
 Day & percent\_active & Polynomial Model\\
\hline
	 59        & 8.285436  &  9.781559\\
	 60        &      NaN  & 16.898091\\
	 61        &      NaN  & 42.345397\\
\end{tabular}


    
     Here we see a high rise in the predicted values of Active Case(\%),
which seems very strange because we already know that China has been
very successful to have control over this epidemic. * It means that -
although our model fits best in this scenario, yet there's some problem
behind this sudden rise in new Cases.

\hypertarget{then-how-our-model-fits-so-perfectly}{%
\subsubsection{Then how our model fits so
perfectly??}\label{then-how-our-model-fits-so-perfectly}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  Here comes the term: \textbf{Model Overfitting}!
\item
  Because, we have trained our model to perform such a higher degree, it
  predicts almost the actual values.
\item
  That's why, though our model fits very accurate on the training and
  testing (that has value of dependent variable belonging to the same
  domain i.e. \textbf{{[}1,58{]}})
\item
  Yet, whenever it gets any new value (60, 61..) due to
  \textbf{overfitting}, our model fails to give right prediction.
\end{itemize}
\end{quote}

 In overfitting, a model works with almost 100\% accuracy, but fails to
give right output on unseen data.

 Hence, we'll have to choose some other degree.. From the degree
accuracy table (we generated early), having a look for \textbf{Degree =
11}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{34}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plm.predictions}\PY{n+nf}{[which}\PY{p}{(}\PY{n}{plm.predictions}\PY{o}{\PYZdl{}}\PY{n}{Degree} \PY{o}{==} \PY{l+m}{11}\PY{p}{)}\PY{p}{,}\PY{n}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llll}
  & Degree & RMSE & RSE & R2\\
\hline
	11 & 11        & 0.5819927 & 0.6649901 & 0.9996465\\
\end{tabular}


    
     It seems a little better, so we'll choose 11 as our degree of
polynomial regression.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{deg} \PY{o}{=} \PY{l+m}{11}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} building polynomial model}
\PY{n}{fit.plm} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{percent\PYZus{}active} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train.data}\PY{p}{)}
\PY{c+c1}{\PYZsh{}summary(fit.plm)}

\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{}\PYZsh{} Prediction table}
\PY{n}{plm.trained} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(} \PY{c+c1}{\PYZsh{} Prediction for training data}
            \PY{n}{train.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{train.data}\PY{p}{)}  \PY{c+c1}{\PYZsh{} predicting the values}
          \PY{p}{)}

\PY{n}{plm.tested} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}  \PY{c+c1}{\PYZsh{} Prediction for tested data}
            \PY{n}{test.data}\PY{n}{[}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{percent\PYZus{}active\PYZdq{}}\PY{p}{)}\PY{n}{]}\PY{p}{,}
            \PY{n}{Pridicted\PYZus{}percent\PYZus{}active} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{test.data}\PY{p}{)}   \PY{c+c1}{\PYZsh{} predicting the values}
         \PY{p}{)}


\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}

\PY{c+c1}{\PYZsh{} Graphs for prediction}
\PY{n}{plm.trainer} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{stat\PYZus{}smooth}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{lm}\PY{p}{,} \PY{n}{formula} \PY{o}{=} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTraining plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)} 

\PY{n}{plm.tester} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{ggplot}\PY{p}{(}\PY{n}{test.data}\PY{p}{,} \PY{n+nf}{aes}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{percent\PYZus{}active}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{geom\PYZus{}point}\PY{p}{(}\PY{p}{)} \PY{o}{+}
              \PY{n+nf}{stat\PYZus{}smooth}\PY{p}{(}\PY{n}{method} \PY{o}{=} \PY{n}{lm}\PY{p}{,} \PY{n}{formula} \PY{o}{=} \PY{n}{y} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{)} \PY{o}{+}   \PY{c+c1}{\PYZsh{} polynomial function}
  
              \PY{c+c1}{\PYZsh{} decoration}
              \PY{n+nf}{labs}\PY{p}{(} \PY{n}{x} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Days\PYZdq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{Active Cases (\PYZpc{})\PYZdq{}}\PY{p}{,} \PY{n}{title} \PY{o}{=} \PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nTesting plot\PYZdq{}}\PY{p}{,} \PY{n}{rName}\PY{p}{,} \PY{n}{sep} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{ \PYZhy{} \PYZdq{}}\PY{p}{)} \PY{p}{)} \PY{o}{+}
              \PY{n+nf}{theme}\PY{p}{(} \PY{n}{plot.title} \PY{o}{=} \PY{n+nf}{element\PYZus{}text}\PY{p}{(}\PY{n}{size} \PY{o}{=} \PY{l+m}{20}\PY{p}{,} \PY{n}{face} \PY{o}{=} \PY{l+s}{\PYZdq{}}\PY{l+s}{bold\PYZdq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{37}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Prediction table at degree = 6}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{plm.trained}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{plm.tested}\PY{p}{,} \PY{l+m}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	53 & 53        & 14.972153 & 15.369157\\
	55 & 55        & 12.224649 & 12.339328\\
	56 & 56        & 11.140171 & 10.925893\\
	57 & 57        &  9.995931 &  9.793102\\
	58 & 58        &  9.084860 &  9.238991\\
\end{tabular}


    
    \begin{tabular}{r|lll}
  & Day & percent\_active & Pridicted\_percent\_active\\
\hline
	39 & 39       & 46.87610 & 47.21327\\
	41 & 41       & 40.39133 & 40.63074\\
	47 & 47       & 25.15992 & 24.96403\\
	50 & 50       & 19.91572 & 19.83759\\
	54 & 54       & 13.31185 & 13.85174\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} New visualization for prediction}
\PY{n}{plm.trainer}
\PY{n}{plm.tester}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_199_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Primary Documentation_files/Primary Documentation_199_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{temp.required}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZdq{}}\PY{l+s}{Polynomial Model\PYZdq{}} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{temp.test}\PY{p}{)}
\PY{n}{temp.required}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
 Day & percent\_active & Polynomial Model\\
\hline
	 59        & 8.285436  &  9.710642\\
	 60        &      NaN  & 11.840712\\
	 61        &      NaN  & 16.487469\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{127}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} So, now it\PYZsq{}s much better!}
\end{Verbatim}
\end{tcolorbox}

    

    \hypertarget{evaluation}{%
\subsection{Evaluation:}\label{evaluation}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  COMPARISION
\item
  FINALIZED ALGO.
\end{itemize}
\end{quote}

    \hypertarget{comparison-among-algorithms}{%
\subsubsection{* Comparison: Among
Algorithms}\label{comparison-among-algorithms}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s evaluate and compare the 4 model algorithms}

\PY{c+c1}{\PYZsh{} Performance (Accurecy) table}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nSupport Vector Machine Regression\PYZdq{}}\PY{p}{)}
\PY{n}{svm.predictions}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nk\PYZhy{}Nearest Neighbour Regression\PYZdq{}}\PY{p}{)}
\PY{n}{knn.predictions}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nLinear Regression\PYZdq{}}\PY{p}{)}
\PY{n}{lm.predictions}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nPolynomial Regression\PYZdq{}}\PY{p}{)}
\PY{n}{plm.predictions}\PY{n+nf}{[which}\PY{p}{(}\PY{n}{plm.predictions}\PY{o}{\PYZdl{}}\PY{n}{Degree} \PY{o}{==} \PY{n}{deg}\PY{p}{)}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZsq{}}\PY{l+s}{RMSE\PYZsq{}}\PY{p}{,} \PY{l+s}{\PYZsq{}}\PY{l+s}{R2\PYZsq{}}\PY{p}{)}\PY{n}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

Support Vector Machine Regression
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

        Error in eval(expr, envir, enclos): object 'svm.predictions' not found
    Traceback:


    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{131}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Creating a comparision table to compare the predicted values by all four models}
\PY{n}{Prediction} \PY{o}{=} \PY{n+nf}{cbind}\PY{p}{(}
                \PY{l+s}{\PYZdq{}}\PY{l+s}{Day\PYZdq{}} \PY{o}{=} \PY{n}{test.data}\PY{o}{\PYZdl{}}\PY{n}{Day}\PY{p}{,}
                \PY{l+s}{\PYZdq{}}\PY{l+s}{Actual Active Case(\PYZpc{})\PYZdq{}} \PY{o}{=} \PY{n}{test.data}\PY{o}{\PYZdl{}}\PY{n}{percent\PYZus{}active}\PY{p}{,}
                \PY{l+s}{\PYZdq{}}\PY{l+s}{Predicted by SVMK\PYZdq{}} \PY{o}{=} \PY{n}{svmk.tested}\PY{o}{\PYZdl{}}\PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{,}
                \PY{l+s}{\PYZdq{}}\PY{l+s}{Predicted by KNN\PYZdq{}} \PY{o}{=} \PY{n}{knn.tested}\PY{o}{\PYZdl{}}\PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{,}
                \PY{l+s}{\PYZdq{}}\PY{l+s}{Predicted by LM\PYZdq{}} \PY{o}{=} \PY{n}{lm.tested}\PY{o}{\PYZdl{}}\PY{n}{Pridicted\PYZus{}percent\PYZus{}active}\PY{p}{,}
                \PY{l+s}{\PYZdq{}}\PY{l+s}{Predicted by Poly LM\PYZdq{}} \PY{o}{=} \PY{n}{plm.tested}\PY{o}{\PYZdl{}}\PY{n}{Pridicted\PYZus{}percent\PYZus{}active}
             \PY{p}{)}
\PY{n}{Prediction}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{llllll}
 Day & Actual Active Case(\%) & Predicted by SVMK & Predicted by KNN & Predicted by LM & Predicted by Poly LM\\
\hline
	  4       & 94.23898 & 92.20595 & 93.96736 & 13.47147 & 94.08485\\
	 13       & 94.72510 & 91.83658 & 94.97576 & 13.21776 & 94.64569\\
	 15       & 93.88484 & 90.64834 & 93.16354 & 13.65628 & 93.36389\\
	 18       & 90.75623 & 88.73618 & 90.77715 & 15.28907 & 90.96662\\
	 28       & 78.15822 & 75.18151 & 77.81573 & 21.86382 & 78.35243\\
	 39       & 46.87610 & 49.87923 & 49.56913 & 38.18960 & 47.21327\\
	 41       & 40.39133 & 43.38354 & 38.31875 & 41.57392 & 40.63074\\
	 47       & 25.15992 & 28.07431 & 25.48533 & 49.52302 & 24.96403\\
	 50       & 19.91572 & 23.13298 & 20.06390 & 52.25991 & 19.83759\\
	 54       & 13.31185 & 15.34209 & 13.77505 & 55.70639 & 13.85174\\
\end{tabular}


    
     \#\#\# * Finalized Algo

Among these \textbf{four} algorithms, our study leads us to choose the
Polynomial Regression for modeling.

\textbf{It is so because:} \textgreater{} * Based on all four models'
performance, it has: 1. Comparatively better values Root Mean Squared
Error (\textbf{RMSE}) and R-Squared values (\textbf{R2}) 2.
Comparatively better predictions\\
\textgreater{} \textgreater{} * In general: 1. Polynomial provides the
\textbf{best approximation of the relationship} between the dependent
and independent variable. 2. A Broad range of function can be fit under
it. 3. Polynomial basically \textbf{fits a wide range of curvature},
hence has a better fit.

\textbf{We have NOT chosen KNN-Regression because:} \textgreater{} 1. It
is a complex algorithm \textgreater{} 2. KNN usually works better for
classification, because it mainly focuses on its surrounding values, for
prediction.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Appending 59th day\PYZsq{}s data to our training dataset}
\PY{n}{train.data} \PY{o}{=} \PY{n+nf}{rbind}\PY{p}{(}\PY{n}{train.data}\PY{p}{,} \PY{n}{temp.test}\PY{n}{[1}\PY{p}{,}\PY{n}{]}\PY{p}{)}            \PY{c+c1}{\PYZsh{} RUN ONCE!!}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{49}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Renaming row sequence}
\PY{n+nf}{row.names}\PY{p}{(}\PY{n}{train.data}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kc}{NULL}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{train.data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llllllll}
  & Day & Confirmed & Deaths & Recovered & Active.Cases & Closed.Cases & percent\_active & percent\_closed\\
\hline
	45 & 55        & 81033     & 3217      & 67910     & 9906      & 71127     & 12.224649 & 87.77535 \\
	46 & 56        & 81058     & 3230      & 68798     & 9030      & 72028     & 11.140171 & 88.85983 \\
	47 & 57        & 81103     & 3241      & 69755     & 8107      & 72996     &  9.995931 & 90.00407 \\
	48 & 58        & 81157     & 3249      & 70535     & 7373      & 73784     &  9.084860 & 90.91514 \\
	49 & 59        & 81251     & 3253      & 71266     & 6732      & 74519     &  8.285436 & 91.71450 \\
	50 & 59        & 81251     & 3253      & 71266     & 6732      & 74519     &  8.285436 & 91.71450 \\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} training once more on updated training dataset}
\PY{n}{fit.plm} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{percent\PYZus{}active} \PY{o}{\PYZti{}} \PY{n+nf}{poly}\PY{p}{(}\PY{n}{Day}\PY{p}{,} \PY{n}{deg}\PY{p}{,} \PY{n}{raw} \PY{o}{=} \PY{k+kc}{TRUE}\PY{p}{)}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train.data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{135}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} At this point, we can clearly see that we should one among Polynomial Regession and KNN algo.}
\PY{c+c1}{\PYZsh{} But, we also know that Polynomial Regression better fits into trend as compared to KNN, as per the visualization, above.}
\PY{c+c1}{\PYZsh{} So, we find that Polynomial regression is best}

\PY{c+c1}{\PYZsh{} Hence, we\PYZsq{}ll be choosing Polynomial Regression with Degree = 16}

\PY{c+c1}{\PYZsh{} now we are ready to go for the last step in our COVID\PYZhy{}19 analysis i.e. Deployment \PYZam{} hence, to get the status of China, in few of the upcoming days:}
\end{Verbatim}
\end{tcolorbox}

    

    \hypertarget{deployment}{%
\subsection{Deployment:}\label{deployment}}

\begin{quote}
\begin{itemize}
\tightlist
\item
  SUMMARY
\item
  FINAL RESULT
\end{itemize}
\end{quote}

    \hypertarget{summary}{%
\subsubsection{* Summary}\label{summary}}

We have trained our model by Polynomial Regression Algorithm
@**Degree:** 11

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{53}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Summary of trained model}
\PY{n+nf}{summary}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{verbatim}

Call:
lm(formula = percent_active ~ poly(Day, deg, raw = TRUE), data = train.data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.95787 -0.18752  0.02621  0.30405  1.48238 

Coefficients:
                               Estimate Std. Error t value Pr(>|t|)    
(Intercept)                   9.194e+01  2.239e+00  41.071   <2e-16 ***
poly(Day, deg, raw = TRUE)1  -5.966e-01  2.646e+00  -0.226    0.823    
poly(Day, deg, raw = TRUE)2   6.316e-01  1.065e+00   0.593    0.557    
poly(Day, deg, raw = TRUE)3  -1.298e-01  2.102e-01  -0.618    0.541    
poly(Day, deg, raw = TRUE)4   1.396e-02  2.373e-02   0.588    0.560    
poly(Day, deg, raw = TRUE)5  -9.612e-04  1.661e-03  -0.579    0.566    
poly(Day, deg, raw = TRUE)6   4.437e-05  7.521e-05   0.590    0.559    
poly(Day, deg, raw = TRUE)7  -1.374e-06  2.243e-06  -0.613    0.544    
poly(Day, deg, raw = TRUE)8   2.786e-08  4.370e-08   0.638    0.528    
poly(Day, deg, raw = TRUE)9  -3.523e-10  5.353e-10  -0.658    0.515    
poly(Day, deg, raw = TRUE)10  2.507e-12  3.738e-12   0.671    0.507    
poly(Day, deg, raw = TRUE)11 -7.650e-15  1.135e-14  -0.674    0.504    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.6593 on 37 degrees of freedom
Multiple R-squared:  0.9997,	Adjusted R-squared:  0.9996 
F-statistic: 1.005e+04 on 11 and 37 DF,  p-value: < 2.2e-16

    \end{verbatim}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Accurecy}
\PY{n}{plm.predictions}\PY{n+nf}{[which}\PY{p}{(}\PY{n}{plm.predictions}\PY{o}{\PYZdl{}}\PY{n}{Degree} \PY{o}{==} \PY{n}{deg}\PY{p}{)}\PY{p}{,}\PY{n}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|llll}
  & Degree & RMSE & RSE & R2\\
\hline
	11 & 11        & 0.5819927 & 0.6649901 & 0.9996465\\
\end{tabular}


    
    

    \textbf{It was all the overview of our model!}

\begin{verbatim}
Now we ready to find the estimate of next one week's status of China about Active Case(%)
\end{verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{69}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Preparing our dataset to store next 7 days\PYZsq{} estimate}

\PY{n}{d} \PY{o}{=} \PY{n+nf}{as.Date}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{21/01/2020\PYZdq{}}\PY{p}{,} \PY{n+nf}{format}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZpc{}d/\PYZpc{}m/\PYZpc{}Y\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{date} \PY{o}{=} \PY{n+nf}{as.character}\PY{p}{(}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{l+m}{1}\PY{o}{:}\PY{l+m}{7}\PY{p}{)} \PY{o}{+} \PY{n}{d}\PY{p}{)}\PY{p}{,} \PY{n+nf}{format}\PY{p}{(}\PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZpc{}d/\PYZpc{}m/\PYZpc{}Y\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}

\PY{n}{finalEstimate} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{data.frame}\PY{p}{(}
                             \PY{n}{Day} \PY{o}{=} \PY{l+m}{59}\PY{o}{:}\PY{l+m}{65}\PY{p}{,}
                             \PY{n}{Date} \PY{o}{=} \PY{n}{date}
                           \PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

     Predicting the estimate for the Active Case percentage, that is likely
to be on the next 1 week:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{70}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{finalEstimate}\PY{o}{\PYZdl{}}\PY{l+s}{\PYZdq{}}\PY{l+s}{Estimated Active Case(\PYZpc{})\PYZdq{}} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit.plm}\PY{p}{,} \PY{n}{finalEstimate}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    

    \#\#\#

Finally! We have estimated the possible \% of Active Cases for next 7
week for China

    \hypertarget{viewing-the-result}{%
\paragraph{Viewing the result:}\label{viewing-the-result}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{71}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{finalEstimate}
\end{Verbatim}
\end{tcolorbox}

    \begin{tabular}{r|lll}
 Day & Date & Estimated Active Case(\%)\\
\hline
	 59         & 22/01/2020 &  8.400352 \\
	 60         & 23/01/2020 &  8.311558 \\
	 61         & 24/01/2020 &  8.699806 \\
	 62         & 25/01/2020 &  9.441795 \\
	 63         & 26/01/2020 & 10.174679 \\
	 64         & 27/01/2020 & 10.159197 \\
	 65         & 28/01/2020 &  8.096655 \\
\end{tabular}


    
    

    \hypertarget{conclusion}{%
\section{Conclusion:}\label{conclusion}}

    So by this whole analysis, we come to a conclusion that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  there will be a little increase in the new cases
\item
  by the end of this week, rate of new confirmed cases will decrease in
  China
\item
  after there the rate of Active Cases(\%) will decrease more fastly
  i.e.~China will attain the control over the COVID-19 in it's provinces
\end{enumerate}

    Hence now China should start to focus on: 1. taking precautions in most
sensitive areas in order to ensure no new COVID-19 case. 2. should focus
even more to maintain the current status, else new cases might increase
again within a few days 3. the majors, that the country has taken till
date, should be followed more strictly, for a few more days

Now, a far more COVID-19 cases are closing as compared to those that are
being reported, newly. It is supposed to decrease even more if China
focused onto the precautions. By the end of this week, the cure of
infected patient will prove to be more beneficial then construction even
more hospitals/isolation centers etc.. 

    \#\#\#

Following word-cloud Visualization tells how fastly, the China is
overcoming the COVID-19

    

    \hypertarget{bibliography}{%
\section{Bibliography:}\label{bibliography}}

    \hypertarget{data-sources}{%
\subsubsection{Data Sources:}\label{data-sources}}

    \begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  World Health Organization
\item
  Johns Hopkins University
\item
  Ministry of Human Resource \& Developmant - India
\item
  Imperial College of London
\item
  Worldometers
\end{enumerate}
\end{quote}

    


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
